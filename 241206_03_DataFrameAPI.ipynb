{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5996689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/09 10:29:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-2-110.ap-northeast-3.compute.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>241206_03_DataFrameAPI</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f17338cf610>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#singleton pattern object builder\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"241206_03_DataFrameAPI\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45e2a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").load(\"data/2015-summary.csv\", interSchema=True, header=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066d58cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(DEST_COUNTRY_NAME,StringType,true),StructField(ORIGIN_COUNTRY_NAME,StringType,true),StructField(count,StringType,true)))\n",
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.schema)\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c9c168",
   "metadata": {},
   "source": [
    "## Row 클래스, 단일 레코드(행)을 나타내는 객체\n",
    "\n",
    "Row(DES_COUNTRY_NAME = 'United States', ORIGIN_COUNTRY_NAME='Romania', count=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc55e537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count='15'),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count='1'),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count='344'),\n",
       " Row(DEST_COUNTRY_NAME='Egypt', ORIGIN_COUNTRY_NAME='United States', count='15'),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='India', count='62')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0dd494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97fd7edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "|    United States|\n",
      "|            Egypt|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#spark DataTable\n",
    "df.select(\"DEST_COUNTRY_NAME\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3aa8ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "402f49ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"DEST_COUNTRY_NAME\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58bc8417",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|         Anguilla|\n",
      "|           Russia|\n",
      "|         Paraguay|\n",
      "|          Senegal|\n",
      "|           Sweden|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#중복 확인\n",
    "df_dup = df.select(\"DEST_COUNTRY_NAME\").dropDuplicates()\n",
    "df_dup.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae69e74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|         Anguilla|\n",
      "|           Russia|\n",
      "|         Paraguay|\n",
      "|          Senegal|\n",
      "|           Sweden|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dup = df.select(\"DEST_COUNTRY_NAME\").dropDuplicates().cache()\n",
    "df_dup.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7f1cace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e81ff79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|             Algeria|      United States|    4|\n",
      "|              Angola|      United States|   15|\n",
      "|            Anguilla|      United States|   41|\n",
      "| Antigua and Barbuda|      United States|  126|\n",
      "|           Argentina|      United States|  180|\n",
      "|               Aruba|      United States|  346|\n",
      "|           Australia|      United States|  329|\n",
      "|             Austria|      United States|   62|\n",
      "|          Azerbaijan|      United States|   21|\n",
      "|             Bahrain|      United States|   19|\n",
      "|            Barbados|      United States|  154|\n",
      "|             Belgium|      United States|  259|\n",
      "|              Belize|      United States|  188|\n",
      "|             Bermuda|      United States|  183|\n",
      "|             Bolivia|      United States|   30|\n",
      "|Bonaire, Sint Eus...|      United States|   58|\n",
      "|              Brazil|      United States|  853|\n",
      "|British Virgin Is...|      United States|  107|\n",
      "|            Bulgaria|      United States|    3|\n",
      "|        Burkina Faso|      United States|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"DEST_COUNTRY_NAME\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7490062d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withInCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "|    United States|            Ireland|  344|        false|\n",
      "|            Egypt|      United States|   15|        false|\n",
      "|    United States|              India|   62|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "#새로 컬럼 추가\n",
    "df3 = df.withColumn('withInCountry',expr(\"ORIGIN_COUNTRY_NAME == DEST_COUNTRY_NAME\"))\n",
    "df3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3541dd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+--------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|Category|\n",
      "+-----------------+-------------------+-----+--------+\n",
      "|    United States|            Romania|   15|   upper|\n",
      "|    United States|            Croatia|    1|   under|\n",
      "|    United States|            Ireland|  344|   upper|\n",
      "|            Egypt|      United States|   15|   upper|\n",
      "|    United States|              India|   62|   upper|\n",
      "+-----------------+-------------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SQL 구문 - CASE WHEN > 수치형 변수 > 명목형 변수로 변환\n",
    "\n",
    "df4 = df.withColumn('Category',expr(\"CASE WHEN count <10 THEN 'under' WHEN count >=10 THEN 'upper' END\"))\n",
    "df4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85ee4bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+--------+------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|Category|withInColumn|\n",
      "+-----------------+-------------------+-----+--------+------------+\n",
      "|    United States|            Romania|   15|   upper|       false|\n",
      "|    United States|            Croatia|    1|   under|       false|\n",
      "|    United States|            Ireland|  344|   upper|       false|\n",
      "|            Egypt|      United States|   15|   upper|       false|\n",
      "|    United States|              India|   62|   upper|       false|\n",
      "+-----------------+-------------------+-----+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5 = df4.withColumn('withInColumn',expr(\"ORIGIN_COUNTRY_NAME==DEST_COUNTRY_NAME\"))\n",
    "df5.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d5e5a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|withInColumn|count|\n",
      "+------------+-----+\n",
      "|        true|    1|\n",
      "|       false|  255|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.groupBy(\"withInColumn\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b11d3b",
   "metadata": {},
   "source": [
    "## Projection 과 Filter\n",
    "```\n",
    "SELECT a,b,c # projection > column > Transformation select('col name')\n",
    "FROM Table A \n",
    "WHERE a>10 #filter > Row > Transformation where('condition')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d9f6eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+--------+------------+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|Category|withInColumn|\n",
      "+--------------------+-------------------+-----+--------+------------+\n",
      "|       United States|            Croatia|    1|   under|       false|\n",
      "|       United States|          Singapore|    1|   under|       false|\n",
      "|             Moldova|      United States|    1|   under|       false|\n",
      "|               Malta|      United States|    1|   under|       false|\n",
      "|             Algeria|      United States|    4|   under|       false|\n",
      "|       United States|          Gibraltar|    1|   under|       false|\n",
      "|Saint Vincent and...|      United States|    1|   under|       false|\n",
      "|            Suriname|      United States|    1|   under|       false|\n",
      "|       United States|             Cyprus|    1|   under|       false|\n",
      "|       United States|           Malaysia|    3|   under|       false|\n",
      "|            Thailand|      United States|    3|   under|       false|\n",
      "|             Liberia|      United States|    2|   under|       false|\n",
      "|             Hungary|      United States|    2|   under|       false|\n",
      "|       United States|            Vietnam|    2|   under|       false|\n",
      "|        Burkina Faso|      United States|    1|   under|       false|\n",
      "|            Djibouti|      United States|    1|   under|       false|\n",
      "|       United States|            Estonia|    1|   under|       false|\n",
      "|       United States|            Hungary|    3|   under|       false|\n",
      "|              Zambia|      United States|    1|   under|       false|\n",
      "|            Malaysia|      United States|    2|   under|       false|\n",
      "+--------------------+-------------------+-----+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter \n",
    "df6 = df5.where('count<5')\n",
    "df6.show()\n",
    "df6.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b963bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+--------+------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|Category|withInColumn|\n",
      "+-----------------+-------------------+-----+--------+------------+\n",
      "|    United States|            Croatia|    1|   under|       false|\n",
      "|    United States|          Singapore|    1|   under|       false|\n",
      "|    United States|          Gibraltar|    1|   under|       false|\n",
      "|    United States|             Cyprus|    1|   under|       false|\n",
      "|    United States|           Malaysia|    3|   under|       false|\n",
      "|    United States|            Vietnam|    2|   under|       false|\n",
      "|    United States|            Estonia|    1|   under|       false|\n",
      "|    United States|            Hungary|    3|   under|       false|\n",
      "|    United States|           Thailand|    4|   under|       false|\n",
      "|    United States|            Liberia|    2|   under|       false|\n",
      "|    United States|              Malta|    2|   under|       false|\n",
      "|    United States|          Lithuania|    1|   under|       false|\n",
      "|    United States|           Bulgaria|    1|   under|       false|\n",
      "|    United States|            Georgia|    1|   under|       false|\n",
      "|    United States|            Bahrain|    1|   under|       false|\n",
      "|    United States|   Papua New Guinea|    1|   under|       false|\n",
      "|    United States|          Greenland|    4|   under|       false|\n",
      "|    United States|          Indonesia|    2|   under|       false|\n",
      "|    United States|         Montenegro|    1|   under|       false|\n",
      "|    United States|            Namibia|    1|   under|       false|\n",
      "+-----------------+-------------------+-----+--------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = df5.where('count<5').where(\"ORIGIN_COUNTRY_NAME != 'United States'\")\n",
    "df6.show()\n",
    "df6.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e14a71c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 44:======================>                                (82 + 3) / 200]\r",
      "\r",
      "[Stage 44:===================================>                  (130 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|ORIGIN_COUNTRY_NAME|sum(count)|\n",
      "+-------------------+----------+\n",
      "|      United States|     41964|\n",
      "|             Canada|      8483|\n",
      "|             Mexico|      7187|\n",
      "|     United Kingdom|      1970|\n",
      "|              Japan|      1496|\n",
      "| Dominican Republic|      1420|\n",
      "|            Germany|      1336|\n",
      "|        The Bahamas|       986|\n",
      "|             France|       952|\n",
      "|              China|       920|\n",
      "+-------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 44:==================================================>   (187 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#프로젝션, 필터링 연습 \n",
    "df5 = df5.withColumn(\"count\", col(\"count\").cast(\"int\")) # count 가 string 이네..? int 로 변경-- cast()\n",
    "# df5.show(10)\n",
    "\n",
    "#국내 여행이 아니면서 가장 횟수가 많은 ORIGIN_COUNTRY_NAME top 10을  추출해보세요\n",
    "top10_trip = df5.where(\"ORIGIN_COUNTRY_NAME != DEST_COUNTRY_NAME\") \\\n",
    "                .groupBy(\"ORIGIN_COUNTRY_NAME\") \\\n",
    "                .sum(\"count\") \\\n",
    "                .sort(\"sum(count)\", ascending=False)\n",
    "top10_trip.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b674829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 46:======================================>               (142 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|ORIGIN_COUNTRY_NAME|count|\n",
      "+-------------------+-----+\n",
      "|            Senegal|    1|\n",
      "|             Sweden|    1|\n",
      "|           Paraguay|    1|\n",
      "|             Russia|    1|\n",
      "|           Anguilla|    1|\n",
      "|           Kiribati|    1|\n",
      "|             Guyana|    1|\n",
      "|          Singapore|    1|\n",
      "|           Malaysia|    1|\n",
      "|        Philippines|    1|\n",
      "+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 46:================================================>     (181 + 3) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#국내 여행이 아니면서 가장 횟수가 적은 ORIGIN_COUNTRY_NAME top 10을  추출해보세요\n",
    "top10_trip_least = df5.where(\"ORIGIN_COUNTRY_NAME != DEST_COUNTRY_NAME\")\\\n",
    "                .groupBy(\"ORIGIN_COUNTRY_NAME\").count()\\\n",
    "                .sort(\"count\", ascending=True)\n",
    "top10_trip_least.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d746b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 48:==================================>                   (126 + 2) / 200]\r",
      "\r",
      "[Stage 48:===============================================>      (177 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+\n",
      "| DEST_COUNTRY_NAME|sum(count)|\n",
      "+------------------+----------+\n",
      "|     United States|    411352|\n",
      "|            Canada|      8399|\n",
      "|            Mexico|      7140|\n",
      "|    United Kingdom|      2025|\n",
      "|             Japan|      1548|\n",
      "|           Germany|      1468|\n",
      "|Dominican Republic|      1353|\n",
      "|       South Korea|      1048|\n",
      "|       The Bahamas|       955|\n",
      "|            France|       935|\n",
      "+------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#도착국가별 count 총합이 가장 많은 top10을 추출해 보세요\n",
    "df7 = df5.groupBy(\"DEST_COUNTRY_NAME\").sum(\"count\").sort('sum(count)',ascending = False)\n",
    "df7.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aef6710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|Category|sum(count)|\n",
      "+--------+----------+\n",
      "|   under|        91|\n",
      "|   upper|    453225|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#카테고리별 분석\n",
    "df6 = df5.withColumn(\"count\", col(\"count\").cast(\"int\"))\n",
    "df6.groupby(\"Category\").sum(\"count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48244a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+------+--------+------------+\n",
      "| DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|Category|withInColumn|\n",
      "+------------------+-------------------+------+--------+------------+\n",
      "|            Mexico|      United States|  7140|   upper|       false|\n",
      "|     United States| Dominican Republic|  1420|   upper|       false|\n",
      "|     United States|      United States|370002|   upper|        true|\n",
      "|           Germany|      United States|  1468|   upper|       false|\n",
      "|            Canada|      United States|  8399|   upper|       false|\n",
      "|Dominican Republic|      United States|  1353|   upper|       false|\n",
      "|             Japan|      United States|  1548|   upper|       false|\n",
      "|     United States|            Germany|  1336|   upper|       false|\n",
      "|     United States|             Mexico|  7187|   upper|       false|\n",
      "|    United Kingdom|      United States|  2025|   upper|       false|\n",
      "|     United States|              Japan|  1496|   upper|       false|\n",
      "|     United States|     United Kingdom|  1970|   upper|       false|\n",
      "|     United States|             Canada|  8483|   upper|       false|\n",
      "|       South Korea|      United States|  1048|   upper|       false|\n",
      "+------------------+-------------------+------+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#비행 횟수가 1000 이상 필터링\n",
    "df6.filter(df6['count']>=1000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01c981df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+\n",
      "| DEST_COUNTRY_NAME|sum(count)|\n",
      "+------------------+----------+\n",
      "|     United States|    411352|\n",
      "|            Canada|      8399|\n",
      "|            Mexico|      7140|\n",
      "|    United Kingdom|      2025|\n",
      "|             Japan|      1548|\n",
      "|           Germany|      1468|\n",
      "|Dominican Republic|      1353|\n",
      "|       South Korea|      1048|\n",
      "|       The Bahamas|       955|\n",
      "|            France|       935|\n",
      "+------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 61:===================================================>  (190 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#상위 10 목적지 국가 \n",
    "df6.groupBy(\"DEST_COUNTRY_NAME\").sum(\"count\").sort(\"sum(count)\", ascending = False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10ed11c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#spark SQL\n",
    "df.createOrReplaceTempView(\"mobility_data\")\n",
    "spark.sql(\"select * from mobility_data\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48fc4a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da658b",
   "metadata": {},
   "source": [
    "# 집계 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "08298d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-2-110.ap-northeast-3.compute.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SecondSparkSessionApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f17338f3b50>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"SecondSparkSessionApp\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0f59ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\",'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load(\"data/emp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "318e6f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- empno: integer (nullable = true)\n",
      " |-- ename: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- mgr: integer (nullable = true)\n",
      " |-- hiredate: string (nullable = true)\n",
      " |-- sal: integer (nullable = true)\n",
      " |-- comm: integer (nullable = true)\n",
      " |-- deptno: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b80a9e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|null|    70|\n",
      "+-----+------+---------+----+----------+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a2fbba26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "| ename|deptno|\n",
      "+------+------+\n",
      "| SMITH|    20|\n",
      "| ALLEN|    30|\n",
      "|  WARD|    30|\n",
      "| JONES|    20|\n",
      "|MARTIN|    30|\n",
      "| BLAKE|    30|\n",
      "| CLARK|    10|\n",
      "| SCOTT|    20|\n",
      "|  KING|    10|\n",
      "|TURNER|    30|\n",
      "| ADAMS|    20|\n",
      "| JAMES|    30|\n",
      "|  FORD|    20|\n",
      "|MILLER|    10|\n",
      "|  JACK|    70|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('ename','deptno').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1f9fa3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|ename|deptno|\n",
      "+-----+------+\n",
      "|SMITH|    20|\n",
      "|JONES|    20|\n",
      "|SCOTT|    20|\n",
      "|ADAMS|    20|\n",
      "| FORD|    20|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('ename','deptno').where('deptno=20').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6141fcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|count(job)|\n",
      "+----------+\n",
      "|        15|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 카운트 집계\n",
    "#null 값이 제외\n",
    "from pyspark.sql.functions import count, countDistinct, approx_count_distinct\n",
    "df.select(count('job')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c441b4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|count(comm)|\n",
      "+-----------+\n",
      "|          4|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#null 값이 포함\n",
    "df.selectExpr('count(comm)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "eae0d45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|      job|\n",
      "+---------+\n",
      "|  ANALYST|\n",
      "| SALESMAN|\n",
      "|    CLERK|\n",
      "|  MANAGER|\n",
      "|PRESIDENT|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('job').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07d162f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 97:=============================================>        (167 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('job').distinct().count() #정확도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0479d211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT job)|\n",
      "+-------------------+\n",
      "|                  5|\n",
      "+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 100:==========================================>          (162 + 2) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(countDistinct('job')).show() #근사치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a7289a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|approx_count_distinct(job)|\n",
      "+--------------------------+\n",
      "|                         5|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(approx_count_distinct('job', 0.1)).show() #지정한 오차가 있어도 성능면에서 유리한 연산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6508b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f4eb88b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|first(ename)|last(ename)|\n",
      "+------------+-----------+\n",
      "|       SMITH|       JACK|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(first('ename'),last('ename')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b803f71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|min(mgr)|max(mgr)|\n",
      "+--------+--------+\n",
      "|    7566|    7902|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# min, max\n",
    "df.select(min('mgr'), max('mgr')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9a0033f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|min(hiredate)|max(hiredate)|\n",
      "+-------------+-------------+\n",
      "|   1980-12-17|   1987-05-23|\n",
      "+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(min('hiredate'), max('hiredate')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ddc89ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+----------+----------+\n",
      "|count(empno)|count(1)|max(ename)|min(ename)|\n",
      "+------------+--------+----------+----------+\n",
      "|          15|      15|      WARD|     ADAMS|\n",
      "+------------+--------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(count(\"empno\"), count(\"*\"), max(\"ename\"), min(\"ename\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4eafcd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|sum(sal)|\n",
      "+--------+\n",
      "|   32225|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(sum(\"sal\")).show() #sal 컬럽의 총합 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6ff5bcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 172:=================================>                   (127 + 2) / 200]\r",
      "\r",
      "[Stage 172:==============================================>      (174 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|sum(DISTINCT sal)|\n",
      "+-----------------+\n",
      "|            27975|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# sal 컬럼값의 중복을 제거하고 합산 \n",
    "\n",
    "df.selectExpr('sum(distinct sal)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6f28b492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+------------------+------------------+\n",
      "|total_tx|total_salary|        avg_salary|       mean_salary|\n",
      "+--------+------------+------------------+------------------+\n",
      "|      15|       32225|2148.3333333333335|2148.3333333333335|\n",
      "+--------+------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#alias \n",
    "dfs = df.select(\n",
    "                count('sal').alias('total_tx'),\n",
    "                sum('sal').alias('total_salary'),\n",
    "                avg('sal').alias('avg_salary'),\n",
    "                expr('mean(sal)').alias('mean_salary')\n",
    ")\n",
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e524ba81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----------+-----------+\n",
      "|total_tx|total_salary|avg_salary|mean_salary|\n",
      "+--------+------------+----------+-----------+\n",
      "|      15|       32225|   2148.33|    2148.33|\n",
      "+--------+------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#round (data, 자릿수)\n",
    "dfs = df.select(\n",
    "                count('sal').alias('total_tx'),\n",
    "                sum('sal').alias('total_salary'),\n",
    "                round(avg('sal'),2).alias('avg_salary'),\n",
    "                round(expr('mean(sal)'),2).alias('mean_salary'),\n",
    "        )\n",
    "dfs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064c5857",
   "metadata": {},
   "source": [
    "# 그룹화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "54bff7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|      job|count|\n",
      "+---------+-----+\n",
      "|  ANALYST|    2|\n",
      "| SALESMAN|    4|\n",
      "|    CLERK|    5|\n",
      "|  MANAGER|    3|\n",
      "|PRESIDENT|    1|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('job').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ff24218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|      job|           SAL_AVG|\n",
      "+---------+------------------+\n",
      "|  ANALYST|            3000.0|\n",
      "| SALESMAN|            1400.0|\n",
      "|    CLERK|            1470.0|\n",
      "|  MANAGER|2758.3333333333335|\n",
      "|PRESIDENT|            5000.0|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#agg() 집계 함수 적용\n",
    "\n",
    "dfs = df.groupBy('job').agg(expr('avg(sal) as SAL_AVG'))\n",
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "de23cc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------------+\n",
      "|      job|round(stddev_pop(sal), 2)|\n",
      "+---------+-------------------------+\n",
      "|  ANALYST|                      0.0|\n",
      "| SALESMAN|                   154.11|\n",
      "|    CLERK|                   880.68|\n",
      "|  MANAGER|                   223.92|\n",
      "|PRESIDENT|                      0.0|\n",
      "+---------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#표준편차 구하기 \n",
    "# 1. sql.function stddev\n",
    "# 2.sql expression\n",
    "\n",
    "#1번째 방법\n",
    "dfs=df.groupBy('job').agg(round(stddev_pop('sal'),2)).alias('SAL_STDDEV')\n",
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "412043eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------------------+\n",
      "|      job|round(stddev_pop(sal) AS `SAL_STDDEV`, 2)|\n",
      "+---------+-----------------------------------------+\n",
      "|  ANALYST|                                      0.0|\n",
      "| SALESMAN|                                   154.11|\n",
      "|    CLERK|                                   880.68|\n",
      "|  MANAGER|                                   223.92|\n",
      "|PRESIDENT|                                      0.0|\n",
      "+---------+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2번째 방법\n",
    "dfs = df.groupBy('job').agg(round(expr('stddev_pop(sal) as SAL_STDDEV'),2))\n",
    "dfs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6255d0",
   "metadata": {},
   "source": [
    "# 윈도우 함수 (Window Function)\n",
    "\n",
    "```\n",
    "순위, 정렬 - rank, row_number, dense_rank\n",
    "누계 - sum, avg, max, min + over()\n",
    "이동평균, 이동합계 - over + rowsBetween, rangeBetween\n",
    "시차, 선행 = lag, lead\n",
    "\n",
    "ex) 세선 구간내 분석, 특정시간 동안 일어난 활동 그룹화\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fe1830",
   "metadata": {},
   "source": [
    "1. partitionBy() > 소그룹으로 나눈다. \n",
    "2. orderBy() > 소그룹 내 정렬\n",
    "3. rowBetween(), rangeBetween()\n",
    "4. over()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "264f65ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.window.WindowSpec at 0x7f1730c0c8e0>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import desc, rank\n",
    "\n",
    "# 순위를 부여하려고 하는 데이터의 범위 > 윈도우 명세 설정\n",
    "windowspec = Window.orderBy(desc('sal'))\n",
    "windowspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "995475a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'RANK() OVER (ORDER BY sal DESC NULLS LAST unspecifiedframe$())'>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 순위 객체\n",
    "salAllRank = rank().over(windowspec)\n",
    "salAllRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "fafca72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "|empno| ename|      job| mgr|  hiredate| sal|comm|deptno|salary_rank|\n",
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "| 7839|  KING|PRESIDENT|null|1981-11-17|5000|null|    10|          1|\n",
      "| 9292|  JACK|    CLERK|7782|1982-01-23|3200|null|    70|          2|\n",
      "| 7788| SCOTT|  ANALYST|7566|1987-04-19|3000|null|    20|          3|\n",
      "| 7902|  FORD|  ANALYST|7566|1981-12-03|3000|null|    20|          3|\n",
      "| 7566| JONES|  MANAGER|7839|1981-04-02|2975|null|    20|          5|\n",
      "| 7698| BLAKE|  MANAGER|7839|1981-05-01|2850|null|    30|          6|\n",
      "| 7782| CLARK|  MANAGER|7839|1981-06-09|2450|null|    10|          7|\n",
      "| 7499| ALLEN| SALESMAN|7698|1981-02-20|1600| 300|    30|          8|\n",
      "| 7844|TURNER| SALESMAN|7698|1981-09-08|1500|   0|    30|          9|\n",
      "| 7934|MILLER|    CLERK|7782|1982-01-23|1300|null|    10|         10|\n",
      "| 7521|  WARD| SALESMAN|7698|1981-02-22|1250| 500|    30|         11|\n",
      "| 7654|MARTIN| SALESMAN|7698|1981-09-28|1250|1400|    30|         11|\n",
      "| 7876| ADAMS|    CLERK|7788|1987-05-23|1100|null|    20|         13|\n",
      "| 7900| JAMES|    CLERK|7698|1981-12-03| 950|null|    30|         14|\n",
      "| 7369| SMITH|    CLERK|7902|1980-12-17| 800|null|    20|         15|\n",
      "+-----+------+---------+----+----------+----+----+------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/09 13:59:44 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "#데이터 프레임에 컬럼으로 추가 > 액션\n",
    "df.withColumn(\"salary_rank\", salAllRank).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "53b0eb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "|empno|salary_rank|\n",
      "+-----+-----------+\n",
      "| 7839|          1|\n",
      "| 9292|          2|\n",
      "| 7788|          3|\n",
      "| 7902|          3|\n",
      "| 7566|          5|\n",
      "| 7698|          6|\n",
      "| 7782|          7|\n",
      "| 7499|          8|\n",
      "| 7844|          9|\n",
      "| 7934|         10|\n",
      "| 7521|         11|\n",
      "| 7654|         11|\n",
      "| 7876|         13|\n",
      "| 7900|         14|\n",
      "| 7369|         15|\n",
      "+-----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/09 13:59:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "df.select('empno', salAllRank.alias(\"salary_rank\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7eaa5a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#집업별 급여 순위\n",
    "#windowspec = Window.orderBy(desc('sal'))\n",
    "windowspec = Window.partitionBy('Job').orderBy(desc('sal'))\n",
    "salJobrank = rank().over(windowspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c140b10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----+----------+\n",
      "|      job| ename| sal|salJobRank|\n",
      "+---------+------+----+----------+\n",
      "|  ANALYST| SCOTT|3000|         1|\n",
      "|  ANALYST|  FORD|3000|         1|\n",
      "| SALESMAN| ALLEN|1600|         1|\n",
      "| SALESMAN|TURNER|1500|         2|\n",
      "| SALESMAN|  WARD|1250|         3|\n",
      "| SALESMAN|MARTIN|1250|         3|\n",
      "|    CLERK|  JACK|3200|         1|\n",
      "|    CLERK|MILLER|1300|         2|\n",
      "|    CLERK| ADAMS|1100|         3|\n",
      "|    CLERK| JAMES| 950|         4|\n",
      "|    CLERK| SMITH| 800|         5|\n",
      "|  MANAGER| JONES|2975|         1|\n",
      "|  MANAGER| BLAKE|2850|         2|\n",
      "|  MANAGER| CLARK|2450|         3|\n",
      "|PRESIDENT|  KING|5000|         1|\n",
      "+---------+------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    'job','ename','sal',\n",
    "    salJobrank.alias('salJobRank')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d27eeaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#부서별 급여 순위\n",
    "#windowspec = Window.orderBy(desc('sal'))\n",
    "windowspec2 = Window.partitionBy('deptno').orderBy(desc('sal'))\n",
    "salDeptrank = rank().over(windowspec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4a6b0de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 459:==================================>                  (132 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-----------+\n",
      "|deptno| ename| sal|salDeptRank|\n",
      "+------+------+----+-----------+\n",
      "|    10|  KING|5000|          1|\n",
      "|    10|MILLER|1300|          2|\n",
      "|    10| CLARK|2450|          3|\n",
      "|    20| SCOTT|3000|          1|\n",
      "|    20|  FORD|3000|          1|\n",
      "|    20| JONES|2975|          1|\n",
      "|    20| ADAMS|1100|          3|\n",
      "|    20| SMITH| 800|          5|\n",
      "|    30| ALLEN|1600|          1|\n",
      "|    30|TURNER|1500|          2|\n",
      "|    30| BLAKE|2850|          2|\n",
      "|    30|  WARD|1250|          3|\n",
      "|    30|MARTIN|1250|          3|\n",
      "|    30| JAMES| 950|          4|\n",
      "|    70|  JACK|3200|          1|\n",
      "+------+------+----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 459:============================================>        (169 + 3) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    'deptno','ename','sal',\n",
    "    salJobrank.alias('salDeptRank')\n",
    ").orderBy('deptno', 'salDeptRank').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5cd99620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------------+\n",
      "| ename|deptno| sal|dept_salary_rank|\n",
      "+------+------+----+----------------+\n",
      "| SCOTT|    20|3000|               1|\n",
      "|  FORD|    20|3000|               1|\n",
      "| JONES|    20|2975|               3|\n",
      "| ADAMS|    20|1100|               4|\n",
      "| SMITH|    20| 800|               5|\n",
      "|  KING|    10|5000|               1|\n",
      "| CLARK|    10|2450|               2|\n",
      "|MILLER|    10|1300|               3|\n",
      "|  JACK|    70|3200|               1|\n",
      "| BLAKE|    30|2850|               1|\n",
      "| ALLEN|    30|1600|               2|\n",
      "|TURNER|    30|1500|               3|\n",
      "|  WARD|    30|1250|               4|\n",
      "|MARTIN|    30|1250|               4|\n",
      "| JAMES|    30| 950|               6|\n",
      "+------+------+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#다른 답\n",
    "\n",
    "#rank()\n",
    "dept_window_spec = Window.partitionBy('deptno').orderBy(desc('sal'))\n",
    "new_df = df.withColumn('dept_salary_rank', rank().over(dept_window_spec))\n",
    "new_df.select(\n",
    "    'ename', 'deptno','sal','dept_salary_rank'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6bbc05a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------------+\n",
      "| ename|deptno| sal|dept_salary_rank|\n",
      "+------+------+----+----------------+\n",
      "| SCOTT|    20|3000|               1|\n",
      "|  FORD|    20|3000|               2|\n",
      "| JONES|    20|2975|               3|\n",
      "| ADAMS|    20|1100|               4|\n",
      "| SMITH|    20| 800|               5|\n",
      "|  KING|    10|5000|               1|\n",
      "| CLARK|    10|2450|               2|\n",
      "|MILLER|    10|1300|               3|\n",
      "|  JACK|    70|3200|               1|\n",
      "| BLAKE|    30|2850|               1|\n",
      "| ALLEN|    30|1600|               2|\n",
      "|TURNER|    30|1500|               3|\n",
      "|  WARD|    30|1250|               4|\n",
      "|MARTIN|    30|1250|               5|\n",
      "| JAMES|    30| 950|               6|\n",
      "+------+------+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#row_number\n",
    "from pyspark.sql.functions import row_number\n",
    "new_df = df.withColumn('dept_salary_rank', row_number().over(dept_window_spec))\n",
    "new_df.select(\n",
    "    'ename', 'deptno','sal','dept_salary_rank'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b946748b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------------+\n",
      "| ename|deptno| sal|dept_salary_rank|\n",
      "+------+------+----+----------------+\n",
      "| SCOTT|    20|3000|               1|\n",
      "|  FORD|    20|3000|               1|\n",
      "| JONES|    20|2975|               2|\n",
      "| ADAMS|    20|1100|               3|\n",
      "| SMITH|    20| 800|               4|\n",
      "|  KING|    10|5000|               1|\n",
      "| CLARK|    10|2450|               2|\n",
      "|MILLER|    10|1300|               3|\n",
      "|  JACK|    70|3200|               1|\n",
      "| BLAKE|    30|2850|               1|\n",
      "| ALLEN|    30|1600|               2|\n",
      "|TURNER|    30|1500|               3|\n",
      "|  WARD|    30|1250|               4|\n",
      "|MARTIN|    30|1250|               4|\n",
      "| JAMES|    30| 950|               5|\n",
      "+------+------+----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dense_rank()\n",
    "from pyspark.sql.functions import dense_rank\n",
    "new_df = df.withColumn('dept_salary_rank', dense_rank().over(dept_window_spec))\n",
    "new_df.select(\n",
    "    'ename', 'deptno','sal','dept_salary_rank'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "7d773a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------+\n",
      "| ename|deptno| sal|sum_salary|\n",
      "+------+------+----+----------+\n",
      "| SMITH|    20| 800|       800|\n",
      "| JONES|    20|2975|      3775|\n",
      "| SCOTT|    20|3000|      6775|\n",
      "| ADAMS|    20|1100|      7875|\n",
      "|  FORD|    20|3000|     10875|\n",
      "| CLARK|    10|2450|      2450|\n",
      "|  KING|    10|5000|      7450|\n",
      "|MILLER|    10|1300|      8750|\n",
      "|  JACK|    70|3200|      3200|\n",
      "| ALLEN|    30|1600|      1600|\n",
      "|  WARD|    30|1250|      2850|\n",
      "|MARTIN|    30|1250|      4100|\n",
      "| BLAKE|    30|2850|      6950|\n",
      "|TURNER|    30|1500|      8450|\n",
      "| JAMES|    30| 950|      9400|\n",
      "+------+------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#누적 급여 계산 \n",
    "\n",
    "sum_window_spec = Window.partitionBy('deptno').orderBy('empno')\n",
    "\n",
    "new_df = df.withColumn('sum_salary', sum('sal').over(sum_window_spec))\n",
    "new_df.select(\n",
    "    'ename', 'deptno','sal','sum_salary'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d6329273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+----------+\n",
      "| ename|deptno| sal|avg_salary|\n",
      "+------+------+----+----------+\n",
      "| SMITH|    20| 800|    2175.0|\n",
      "| JONES|    20|2975|    2175.0|\n",
      "| SCOTT|    20|3000|    2175.0|\n",
      "| ADAMS|    20|1100|    2175.0|\n",
      "|  FORD|    20|3000|    2175.0|\n",
      "| CLARK|    10|2450|   2916.67|\n",
      "|  KING|    10|5000|   2916.67|\n",
      "|MILLER|    10|1300|   2916.67|\n",
      "|  JACK|    70|3200|    3200.0|\n",
      "| ALLEN|    30|1600|   1566.67|\n",
      "|  WARD|    30|1250|   1566.67|\n",
      "|MARTIN|    30|1250|   1566.67|\n",
      "| BLAKE|    30|2850|   1566.67|\n",
      "|TURNER|    30|1500|   1566.67|\n",
      "| JAMES|    30| 950|   1566.67|\n",
      "+------+------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 부서별 평균 급여 계산 \n",
    "\n",
    "avg_window_spec = Window.partitionBy('deptno')\n",
    "\n",
    "new_df = df.withColumn('avg_salary', round(avg('sal').over(avg_window_spec),2))\n",
    "new_df.select(\n",
    "    'ename', 'deptno','sal','avg_salary'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb73c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL SELECT 문\n",
    "\n",
    "SELECT\n",
    "ename,deptno, sal, #projection\n",
    "avg('sal').over(partition by deptno) as dept_avg_salary\n",
    "from emp; #filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a8838c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+---------------+\n",
      "| ename|deptno| sal|dept_avg_salary|\n",
      "+------+------+----+---------------+\n",
      "| SMITH|    20| 800|         2175.0|\n",
      "| JONES|    20|2975|         2175.0|\n",
      "| SCOTT|    20|3000|         2175.0|\n",
      "| ADAMS|    20|1100|         2175.0|\n",
      "|  FORD|    20|3000|         2175.0|\n",
      "| CLARK|    10|2450|        2916.67|\n",
      "|  KING|    10|5000|        2916.67|\n",
      "|MILLER|    10|1300|        2916.67|\n",
      "|  JACK|    70|3200|         3200.0|\n",
      "| ALLEN|    30|1600|        1566.67|\n",
      "|  WARD|    30|1250|        1566.67|\n",
      "|MARTIN|    30|1250|        1566.67|\n",
      "| BLAKE|    30|2850|        1566.67|\n",
      "|TURNER|    30|1500|        1566.67|\n",
      "| JAMES|    30| 950|        1566.67|\n",
      "+------+------+----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"emp\")  # 'emp' 테이블 생성\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    ename, \n",
    "    deptno, \n",
    "    sal, \n",
    "    ROUND(AVG(sal) OVER (PARTITION BY deptno), 2) AS dept_avg_salary\n",
    "FROM emp\n",
    "\"\"\"\n",
    "\n",
    "result_df = spark.sql(query)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "6d9d028b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-----------+-----------+\n",
      "| ename|deptno| sal|prev_salary|next_salary|\n",
      "+------+------+----+-----------+-----------+\n",
      "| SMITH|    20| 800|       null|       2975|\n",
      "| JONES|    20|2975|        800|       3000|\n",
      "| SCOTT|    20|3000|       2975|       1100|\n",
      "| ADAMS|    20|1100|       3000|       3000|\n",
      "|  FORD|    20|3000|       1100|       null|\n",
      "| CLARK|    10|2450|       null|       5000|\n",
      "|  KING|    10|5000|       2450|       1300|\n",
      "|MILLER|    10|1300|       5000|       null|\n",
      "|  JACK|    70|3200|       null|       null|\n",
      "| ALLEN|    30|1600|       null|       1250|\n",
      "|  WARD|    30|1250|       1600|       1250|\n",
      "|MARTIN|    30|1250|       1250|       2850|\n",
      "| BLAKE|    30|2850|       1250|       1500|\n",
      "|TURNER|    30|1500|       2850|        950|\n",
      "| JAMES|    30| 950|       1500|       null|\n",
      "+------+------+----+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lead, lag 이전 급여, 이후 급여\n",
    "from pyspark.sql.functions import lag,lead\n",
    "\n",
    "row_window_spec = Window.partitionBy('deptno').orderBy('empno')\n",
    "lead_lag_new_avg_df = df.withColumn('prev_salary', lag('sal').over(row_window_spec))\\\n",
    "                .withColumn('next_salary', lead('sal').over(row_window_spec))\n",
    "\n",
    "lead_lag_new_avg_df.select('ename','deptno','sal','prev_salary','next_salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "c12dcdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+-----------+-----------+\n",
      "| ename|deptno| sal|prev_salary|next_salary|\n",
      "+------+------+----+-----------+-----------+\n",
      "| SMITH|    20| 800|       null|       2975|\n",
      "| JONES|    20|2975|        800|       3000|\n",
      "| SCOTT|    20|3000|       2975|       1100|\n",
      "| ADAMS|    20|1100|       3000|       3000|\n",
      "|  FORD|    20|3000|       1100|       null|\n",
      "| CLARK|    10|2450|       null|       5000|\n",
      "|  KING|    10|5000|       2450|       1300|\n",
      "|MILLER|    10|1300|       5000|       null|\n",
      "|  JACK|    70|3200|       null|       null|\n",
      "| ALLEN|    30|1600|       null|       1250|\n",
      "|  WARD|    30|1250|       1600|       1250|\n",
      "|MARTIN|    30|1250|       1250|       2850|\n",
      "| BLAKE|    30|2850|       1250|       1500|\n",
      "|TURNER|    30|1500|       2850|        950|\n",
      "| JAMES|    30| 950|       1500|       null|\n",
      "+------+------+----+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SQL SELECT 문\n",
    "df.createOrReplaceTempView(\"emp\") \n",
    "\n",
    "query2 = '''\n",
    "SELECT ename, deptno, sal,\n",
    "LAG(sal) OVER(PARTITION  BY deptno order by empno) as prev_salary,\n",
    "LEAD(sal) OVER (PARTITION BY deptno order by empno) as next_salary\n",
    "FROM emp;\n",
    "'''\n",
    "result_df2 = spark.sql(query2)\n",
    "result_df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51df277",
   "metadata": {},
   "source": [
    "# rollup, cube\n",
    "\n",
    "```\n",
    "over(), groupby()\n",
    "rollup: 계층적집계, 부분합(subtotal), 총합(grandtotal)\n",
    "cube: 모든 값으로 부분합, 결합 가능합 모든 값의 부분합을 구한다\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "df114ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[empno: int, ename: string, job: string, mgr: int, hiredate: string, sal: int, comm: int, deptno: int]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "12765b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|count(1)|sum(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|    10|    CLERK|       1|    1300|\n",
      "|    10|  MANAGER|       1|    2450|\n",
      "|    10|PRESIDENT|       1|    5000|\n",
      "|    20|  ANALYST|       2|    6000|\n",
      "|    20|    CLERK|       2|    1900|\n",
      "|    20|  MANAGER|       1|    2975|\n",
      "|    30|    CLERK|       1|     950|\n",
      "|    30|  MANAGER|       1|    2850|\n",
      "|    30| SALESMAN|       4|    5600|\n",
      "|    70|    CLERK|       1|    3200|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#그룹화 > 소계\n",
    "\n",
    "df.groupBy('deptno','job')\\\n",
    "    .agg(count('*'), sum('sal'))\\\n",
    "    .orderBy('deptno','job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "63991f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|count(1)|sum(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|  null|     null|      15|   32225|\n",
      "|    10|     null|       3|    8750|\n",
      "|    10|    CLERK|       1|    1300|\n",
      "|    10|  MANAGER|       1|    2450|\n",
      "|    10|PRESIDENT|       1|    5000|\n",
      "|    20|     null|       5|   10875|\n",
      "|    20|  ANALYST|       2|    6000|\n",
      "|    20|    CLERK|       2|    1900|\n",
      "|    20|  MANAGER|       1|    2975|\n",
      "|    30|     null|       6|    9400|\n",
      "|    30|    CLERK|       1|     950|\n",
      "|    30|  MANAGER|       1|    2850|\n",
      "|    30| SALESMAN|       4|    5600|\n",
      "|    70|     null|       1|    3200|\n",
      "|    70|    CLERK|       1|    3200|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rollup\n",
    "df.rollup('deptno','job')\\\n",
    "    .agg(count('*'), sum('sal'))\\\n",
    "    .orderBy('deptno','job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a6f4d531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+--------+\n",
      "|deptno|      job|count(1)|sum(sal)|\n",
      "+------+---------+--------+--------+\n",
      "|  null|     null|      15|   32225|\n",
      "|  null|  ANALYST|       2|    6000|\n",
      "|  null|    CLERK|       5|    7350|\n",
      "|  null|  MANAGER|       3|    8275|\n",
      "|  null|PRESIDENT|       1|    5000|\n",
      "|  null| SALESMAN|       4|    5600|\n",
      "|    10|     null|       3|    8750|\n",
      "|    10|    CLERK|       1|    1300|\n",
      "|    10|  MANAGER|       1|    2450|\n",
      "|    10|PRESIDENT|       1|    5000|\n",
      "|    20|     null|       5|   10875|\n",
      "|    20|  ANALYST|       2|    6000|\n",
      "|    20|    CLERK|       2|    1900|\n",
      "|    20|  MANAGER|       1|    2975|\n",
      "|    30|     null|       6|    9400|\n",
      "|    30|    CLERK|       1|     950|\n",
      "|    30|  MANAGER|       1|    2850|\n",
      "|    30| SALESMAN|       4|    5600|\n",
      "|    70|     null|       1|    3200|\n",
      "|    70|    CLERK|       1|    3200|\n",
      "+------+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cube\n",
    "df.cube('deptno','job')\\\n",
    "    .agg(count('*'), sum('sal'))\\\n",
    "    .orderBy('deptno','job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "470358ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+----------+----------+\n",
      "|deptno|      job|count|min_salary|max_salary|\n",
      "+------+---------+-----+----------+----------+\n",
      "|  null|     null|   15|       800|      5000|\n",
      "|    10|     null|    3|      1300|      5000|\n",
      "|    10|    CLERK|    1|      1300|      1300|\n",
      "|    10|  MANAGER|    1|      2450|      2450|\n",
      "|    10|PRESIDENT|    1|      5000|      5000|\n",
      "|    20|     null|    5|       800|      3000|\n",
      "|    20|  ANALYST|    2|      3000|      3000|\n",
      "|    20|    CLERK|    2|       800|      1100|\n",
      "|    20|  MANAGER|    1|      2975|      2975|\n",
      "|    30|     null|    6|       950|      2850|\n",
      "|    30|    CLERK|    1|       950|       950|\n",
      "|    30|  MANAGER|    1|      2850|      2850|\n",
      "|    30| SALESMAN|    4|      1250|      1600|\n",
      "|    70|     null|    1|      3200|      3200|\n",
      "|    70|    CLERK|    1|      3200|      3200|\n",
      "+------+---------+-----+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#롤업 -> 대,중분류 최대/최소값\n",
    "\n",
    "df.rollup('deptno','job')\\\n",
    "    .agg(count('*').alias('count'),\n",
    "         min('sal').alias('min_salary'), \n",
    "         max('sal').alias('max_salary'))\\\n",
    "    .orderBy('deptno','job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "837f4fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+----------+\n",
      "|deptno|      job|max_salary|min_salary|\n",
      "+------+---------+----------+----------+\n",
      "|  null|     null|      5000|       800|\n",
      "|    10|     null|      5000|      1300|\n",
      "|    10|    CLERK|      1300|      1300|\n",
      "|    10|  MANAGER|      2450|      2450|\n",
      "|    10|PRESIDENT|      5000|      5000|\n",
      "|    20|     null|      3000|       800|\n",
      "|    20|  ANALYST|      3000|      3000|\n",
      "|    20|    CLERK|      1100|       800|\n",
      "|    20|  MANAGER|      2975|      2975|\n",
      "|    30|     null|      2850|       950|\n",
      "|    30|    CLERK|       950|       950|\n",
      "|    30|  MANAGER|      2850|      2850|\n",
      "|    30| SALESMAN|      1600|      1250|\n",
      "|    70|     null|      3200|      3200|\n",
      "|    70|    CLERK|      3200|      3200|\n",
      "+------+---------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SQL SELECT 문\n",
    "df.createOrReplaceTempView(\"emp\") \n",
    "\n",
    "query = '''\n",
    "SELECT deptno,job,\n",
    "max(sal) as max_salary,\n",
    "min(sal) as min_salary\n",
    "FROM emp\n",
    "group by rollup(deptno, job)\n",
    "order by deptno, job;\n",
    "'''\n",
    "result_df = spark.sql(query)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "b69246ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------+\n",
      "|      job|avg_salary|total_salary|\n",
      "+---------+----------+------------+\n",
      "|     null|   2148.33|       32225|\n",
      "|  ANALYST|    3000.0|        6000|\n",
      "|    CLERK|    1470.0|        7350|\n",
      "|  MANAGER|   2758.33|        8275|\n",
      "|PRESIDENT|    5000.0|        5000|\n",
      "| SALESMAN|    1400.0|        5600|\n",
      "+---------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# job 별 평균 급여 job, avg_salary, total_salary\n",
    "df.rollup('job')\\\n",
    "    .agg(round(avg('sal'),2).alias('avg_salary'),\n",
    "         sum('sal').alias('total_salary')).orderBy('job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "aceb8ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------+\n",
      "|      job|avg_salary|total_salary|\n",
      "+---------+----------+------------+\n",
      "|     null|   2148.33|       32225|\n",
      "|  ANALYST|    3000.0|        6000|\n",
      "|    CLERK|    1470.0|        7350|\n",
      "|  MANAGER|   2758.33|        8275|\n",
      "|PRESIDENT|    5000.0|        5000|\n",
      "| SALESMAN|    1400.0|        5600|\n",
      "+---------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SQL SELECT 문\n",
    "#df.createOrReplaceTempView(\"emp\") \n",
    "\n",
    "query = '''\n",
    "SELECT job,\n",
    "round(avg(sal),2) as avg_salary,\n",
    "sum(sal) as total_salary\n",
    "FROM emp\n",
    "group by rollup(job)\n",
    "order by job;\n",
    "'''\n",
    "result_df = spark.sql(query)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "63e460dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+----------+\n",
      "|deptno|      job|avg_salary|max_salary|\n",
      "+------+---------+----------+----------+\n",
      "|  null|     null|   2148.33|      5000|\n",
      "|  null|  ANALYST|    3000.0|      3000|\n",
      "|  null|    CLERK|    1470.0|      3200|\n",
      "|  null|  MANAGER|   2758.33|      2975|\n",
      "|  null|PRESIDENT|    5000.0|      5000|\n",
      "|  null| SALESMAN|    1400.0|      1600|\n",
      "|    10|     null|   2916.67|      5000|\n",
      "|    10|    CLERK|    1300.0|      1300|\n",
      "|    10|  MANAGER|    2450.0|      2450|\n",
      "|    10|PRESIDENT|    5000.0|      5000|\n",
      "|    20|     null|    2175.0|      3000|\n",
      "|    20|  ANALYST|    3000.0|      3000|\n",
      "|    20|    CLERK|     950.0|      1100|\n",
      "|    20|  MANAGER|    2975.0|      2975|\n",
      "|    30|     null|   1566.67|      2850|\n",
      "|    30|    CLERK|     950.0|       950|\n",
      "|    30|  MANAGER|    2850.0|      2850|\n",
      "|    30| SALESMAN|    1400.0|      1600|\n",
      "|    70|     null|    3200.0|      3200|\n",
      "|    70|    CLERK|    3200.0|      3200|\n",
      "+------+---------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# deptno, job 평균급여, 최대급여를 모두 소계를 냅니다. - cube\n",
    "\n",
    "df.cube('deptno','job')\\\n",
    "    .agg(round(avg('sal'),2).alias('avg_salary'),\n",
    "    max('sal').alias('max_salary'))\\\n",
    "    .orderBy('deptno','job').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "dc53e72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+----------+\n",
      "|deptno|      job|avg_salary|max_salary|\n",
      "+------+---------+----------+----------+\n",
      "|  null|     null|   2148.33|      5000|\n",
      "|  null|  ANALYST|    3000.0|      3000|\n",
      "|  null|    CLERK|    1470.0|      3200|\n",
      "|  null|  MANAGER|   2758.33|      2975|\n",
      "|  null|PRESIDENT|    5000.0|      5000|\n",
      "|  null| SALESMAN|    1400.0|      1600|\n",
      "|    10|     null|   2916.67|      5000|\n",
      "|    10|    CLERK|    1300.0|      1300|\n",
      "|    10|  MANAGER|    2450.0|      2450|\n",
      "|    10|PRESIDENT|    5000.0|      5000|\n",
      "|    20|     null|    2175.0|      3000|\n",
      "|    20|  ANALYST|    3000.0|      3000|\n",
      "|    20|    CLERK|     950.0|      1100|\n",
      "|    20|  MANAGER|    2975.0|      2975|\n",
      "|    30|     null|   1566.67|      2850|\n",
      "|    30|    CLERK|     950.0|       950|\n",
      "|    30|  MANAGER|    2850.0|      2850|\n",
      "|    30| SALESMAN|    1400.0|      1600|\n",
      "|    70|     null|    3200.0|      3200|\n",
      "|    70|    CLERK|    3200.0|      3200|\n",
      "+------+---------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SQL SELECT 문\n",
    "#df.createOrReplaceTempView(\"emp\") \n",
    "\n",
    "query = '''\n",
    "SELECT deptno, job,\n",
    "round(avg(sal),2) as avg_salary,\n",
    "max(sal) as max_salary\n",
    "FROM emp\n",
    "group by cube(deptno, job)\n",
    "order by deptno, job;\n",
    "'''\n",
    "result_df = spark.sql(query)\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "e784170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark_start",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
