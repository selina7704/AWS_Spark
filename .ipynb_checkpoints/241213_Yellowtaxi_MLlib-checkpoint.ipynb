{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53159118",
   "metadata": {},
   "source": [
    "# YellowTaxi ALS\n",
    "\n",
    "1. 필요한 라이브러리 불러오기 \n",
    "2. 데이터 준비하기 \n",
    "    - 2.1 데이터 파일 불러오기\n",
    "    - 2.2 데이터 전처리\n",
    "    - 2.3 컬럼 변경 if needed\n",
    "3. 데이터 분할\n",
    "4. ALS 모델 생성 및 설정\n",
    "5. 예측\n",
    "6. 평가\n",
    "7. 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cec5f8",
   "metadata": {},
   "source": [
    "# 목표 정의 \n",
    "\n",
    "- ALS 적용시 요소 준비 - 어떠한 컬럼을 추출하고, 어떠한 것을 추천받고 싶은지?\n",
    "- 내가 택시 기사라면, 회사라면, 사용자라면? \n",
    "\n",
    "1. 택시 승하차 지역에 대한 예상 요금 예측 추천 \n",
    "- 사용자(user): PULocationID\n",
    "- 아이템(item): DOLocationID\n",
    "- 평점(rating): total_amount "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3361ed25",
   "metadata": {},
   "source": [
    "# 1. 필요한 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cddcedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/13 18:08:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/13 18:08:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-2-110.ap-northeast-3.compute.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>241213_Yellowtaxi_MLlib</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f1d48c0a5e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"241213_Yellowtaxi_MLlib\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c124913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de2b436",
   "metadata": {},
   "source": [
    "# 2. 데이터 준비하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d67f97",
   "metadata": {},
   "source": [
    "## 2.1 데이터 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b8122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "trip_files = '/trips/*'\n",
    "zone_file = 'taxi+_zone_lookup.csv'\n",
    "directory = os.path.join(os.getcwd(), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243425a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trips_df = spark.read.csv(f'file:///{directory}/{trip_files}', inferSchema=True, header=True)\n",
    "zone_df = spark.read.csv(f'file:///{directory}/{zone_file}', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1885a1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df.printSchema()\n",
    "zone_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e77064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       2| 2021-03-01 00:22:02|  2021-03-01 00:23:22|              1|          0.0|         1|                 N|         264|         264|           2|        3.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.3|                 0.0|\n",
      "|       2| 2021-03-01 00:24:48|  2021-03-01 00:24:56|              1|          0.0|         1|                 N|         152|         152|           2|        2.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         3.8|                 0.0|\n",
      "|       2| 2021-03-01 00:25:17|  2021-03-01 00:31:01|              1|          0.0|         1|                 N|         152|         152|           2|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.8|                 0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+----------+-------+--------------------+------------+\n",
      "|LocationID|Borough|                Zone|service_zone|\n",
      "+----------+-------+--------------------+------------+\n",
      "|         1|    EWR|      Newark Airport|         EWR|\n",
      "|         2| Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|  Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "+----------+-------+--------------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df.show(3)\n",
    "zone_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a18a3cf",
   "metadata": {},
   "source": [
    "## 2.2 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2798d09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+\n",
      "|PULocationID|DOLocationID|total_amount|\n",
      "+------------+------------+------------+\n",
      "|         264|         264|         4.3|\n",
      "|         152|         152|         3.8|\n",
      "|         152|         152|         4.8|\n",
      "|         138|         265|       70.07|\n",
      "|          68|         264|       11.16|\n",
      "|         239|         262|       18.59|\n",
      "|         186|          91|        43.8|\n",
      "|         132|         265|        32.3|\n",
      "|         138|         141|       43.67|\n",
      "|         138|          50|        46.1|\n",
      "|         132|         123|        45.3|\n",
      "|         140|           7|        19.3|\n",
      "|         239|         238|        14.8|\n",
      "|         116|          41|        12.8|\n",
      "|          74|          41|         5.3|\n",
      "|         239|         144|        17.3|\n",
      "|         132|          91|       47.25|\n",
      "|         239|          50|        12.8|\n",
      "|         132|         230|       61.42|\n",
      "|         229|          48|       14.16|\n",
      "+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 필요한 컬럼만 추출 \n",
    "\n",
    "trips_df = trips_df.select([\"PULocationID\", \"DOLocationID\", \"total_amount\"])\n",
    "trips_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cf12f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:===================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+\n",
      "|PULocationID|DOLocationID|total_amount|\n",
      "+------------+------------+------------+\n",
      "|           0|           0|           0|\n",
      "+------------+------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# null 값 체크\n",
    "null_counts = trips_df.select(\n",
    "    [\n",
    "    sum(when(col(c).isNull() | isnan(c),1).otherwise(0)).alias(c) for c in trips_df.columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "null_counts.show()\n",
    "\n",
    "#trips_df = trips_df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcb6c865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:===================================================>     (10 + 1) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-------------------+\n",
      "|summary|      PULocationID|      DOLocationID|       total_amount|\n",
      "+-------+------------------+------------------+-------------------+\n",
      "|  count|             68820|             68820|              68820|\n",
      "|   mean|163.31117407730312|161.17672188317349|-14.490561464692082|\n",
      "| stddev| 66.81615783677348| 70.65807406291414| 17.161514139828355|\n",
      "|    min|                 1|                 1|             -647.8|\n",
      "|    max|               265|               265|               -0.3|\n",
      "+-------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# total_amount 마이너스 값이 있나 확인 -- 48820 개? \n",
    "negative_amount = trips_df.filter(col(\"total_amount\") < 0)\n",
    "negative_amount.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b51a70f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '`total_amount`' given input columns: [itemId, rating, userId];\n'Project [userId#795, itemId#799, rating#803, CASE WHEN ('total_amount < 0) THEN 0 ELSE 'total_amount END AS total_amount#1048]\n+- Project [userId#795, itemId#799, total_amount#608 AS rating#803]\n   +- Project [userId#795, DOLocationID#24 AS itemId#799, total_amount#608]\n      +- Project [PULocationID#23 AS userId#795, DOLocationID#24, total_amount#608]\n         +- Project [PULocationID#23, DOLocationID#24, CASE WHEN (total_amount#421 < cast(0 as double)) THEN cast(0 as double) ELSE total_amount#421 END AS total_amount#608]\n            +- Project [PULocationID#23, DOLocationID#24, CASE WHEN (total_amount#32 < cast(0 as double)) THEN cast(0 as double) ELSE total_amount#32 END AS total_amount#421]\n               +- Project [PULocationID#23, DOLocationID#24, total_amount#32]\n                  +- Relation[VendorID#16,tpep_pickup_datetime#17,tpep_dropoff_datetime#18,passenger_count#19,trip_distance#20,RatecodeID#21,store_and_fwd_flag#22,PULocationID#23,DOLocationID#24,payment_type#25,fare_amount#26,extra#27,mta_tax#28,tip_amount#29,tolls_amount#30,improvement_surcharge#31,total_amount#32,congestion_surcharge#33] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 마이너스인 금액을 0으로 대체\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trips_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrips_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtotal_amount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mwhen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtotal_amount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43motherwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtotal_amount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m trips_df\u001b[38;5;241m.\u001b[39mdescribe()\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.py:2455\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2425\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2426\u001b[0m \u001b[38;5;124;03mReturns a new :class:`DataFrame` by adding a column or replacing the\u001b[39;00m\n\u001b[1;32m   2427\u001b[0m \u001b[38;5;124;03mexisting column that has the same name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2452\u001b[0m \n\u001b[1;32m   2453\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol should be Column\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`total_amount`' given input columns: [itemId, rating, userId];\n'Project [userId#795, itemId#799, rating#803, CASE WHEN ('total_amount < 0) THEN 0 ELSE 'total_amount END AS total_amount#1048]\n+- Project [userId#795, itemId#799, total_amount#608 AS rating#803]\n   +- Project [userId#795, DOLocationID#24 AS itemId#799, total_amount#608]\n      +- Project [PULocationID#23 AS userId#795, DOLocationID#24, total_amount#608]\n         +- Project [PULocationID#23, DOLocationID#24, CASE WHEN (total_amount#421 < cast(0 as double)) THEN cast(0 as double) ELSE total_amount#421 END AS total_amount#608]\n            +- Project [PULocationID#23, DOLocationID#24, CASE WHEN (total_amount#32 < cast(0 as double)) THEN cast(0 as double) ELSE total_amount#32 END AS total_amount#421]\n               +- Project [PULocationID#23, DOLocationID#24, total_amount#32]\n                  +- Relation[VendorID#16,tpep_pickup_datetime#17,tpep_dropoff_datetime#18,passenger_count#19,trip_distance#20,RatecodeID#21,store_and_fwd_flag#22,PULocationID#23,DOLocationID#24,payment_type#25,fare_amount#26,extra#27,mta_tax#28,tip_amount#29,tolls_amount#30,improvement_surcharge#31,total_amount#32,congestion_surcharge#33] csv\n"
     ]
    }
   ],
   "source": [
    "# 마이너스인 금액을 0으로 대체\n",
    "trips_df = trips_df.withColumn(\\\n",
    "                    \"total_amount\", \\\n",
    "                    when(col(\"total_amount\")<0, 0)\\\n",
    "                    .otherwise(col(\"total_amount\")))\n",
    "trips_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99729f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 이상치 처리? \n",
    "# from pyspark.sql.functions import col\n",
    "\n",
    "# # IQR 방식으로 이상치 제거\n",
    "# quantiles = trips_df.approxQuantile(\"total_amount\", [0.25, 0.75], 0.05)\n",
    "# Q1, Q3 = quantiles[0], quantiles[1]\n",
    "# IQR = Q3 - Q1\n",
    "# lower_bound = Q1 - 1.5 * IQR\n",
    "# upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# # 이상치 데이터 제거\n",
    "# cleaned_trips_df = trips_df.filter((col(\"total_amount\") >= lower_bound) & (col(\"total_amount\") <= upper_bound))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3fa7d7",
   "metadata": {},
   "source": [
    "## 2.3 컬럼 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "015dfe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|userId|itemId|rating|\n",
      "+------+------+------+\n",
      "|   264|   264|   4.3|\n",
      "|   152|   152|   3.8|\n",
      "|   152|   152|   4.8|\n",
      "|   138|   265| 70.07|\n",
      "|    68|   264| 11.16|\n",
      "+------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df = trips_df.withColumnRenamed(\"PULocationID\", \"userId\") \\\n",
    "                   .withColumnRenamed(\"DOLocationID\", \"itemId\") \\\n",
    "                   .withColumnRenamed(\"total_amount\", \"rating\")\n",
    "trips_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cb8ced",
   "metadata": {},
   "source": [
    "# 3. 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "050f8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "train_df,test_df =trips_df.randomSplit([train_ratio, test_ratio], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbd523a",
   "metadata": {},
   "source": [
    "# 4. ALS 모델 생성 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01a84780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/13 18:17:11 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "24/12/13 18:17:11 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "24/12/13 18:17:11 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "24/12/13 18:17:11 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ALS 모델 생성\n",
    "als = ALS(\n",
    "    maxIter=5,\n",
    "    regParam=0.1,\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"itemId\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy='drop' # 결측값 방지\n",
    ")\n",
    "\n",
    "als_model =als.fit(trips_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15f8a02",
   "metadata": {},
   "source": [
    "# 5. 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64e2c5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 65:================================================>     (179 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+----------+\n",
      "|userId|itemId|rating|prediction|\n",
      "+------+------+------+----------+\n",
      "|   148|   148|   0.0| 12.394571|\n",
      "|   148|   148|   0.0| 12.394571|\n",
      "|   148|   148|   0.3| 12.394571|\n",
      "|   148|   148|   5.8| 12.394571|\n",
      "|   148|   148|   5.8| 12.394571|\n",
      "+------+------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "predictions = als_model.transform(test_df)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be40f242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 85:=================================================>    (185 + 2) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|            rating|        prediction|\n",
      "+-------+------------------+------------------+\n",
      "|  count|           3000671|           3000671|\n",
      "|   mean|18.775539527664378|18.799384515284494|\n",
      "| stddev|14.806227867984497|13.479430610641616|\n",
      "|    min|               0.0|         4.5543995|\n",
      "|    max|           7661.28|         1878.6104|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.select(\"rating\",\"prediction\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e8768a",
   "metadata": {},
   "source": [
    "# 6. 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebf3b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f50a779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.088887752388507"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298bc97",
   "metadata": {},
   "source": [
    "### 평가 값의 해석:\n",
    "- 실제 값과 평균적으로 약 10.09 만큼 차이가 난다는 의미\n",
    "- RMSE 가 낮을수록 모델이 잘 예측한다고 평가 -> 실제 값 사이에 상당한 차이가 있음 ;;\n",
    "- 고려사항: 모델 성능이 좋지 않음 -> 전처리 개선(이상치 처리, 정규화 등)이나 하이퍼파라미터 튜닝 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102c37c6",
   "metadata": {},
   "source": [
    "# 7. 추천 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df03befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 추천 생성 (예: 승차 지역에 대한 하차 지역 추천)\n",
    "user_df = trips_df.select(\"userId\").distinct() # 사용자 데이터 (승차 지역)\n",
    "recommendations = als_model.recommendForUserSubset(user_df, 10) # 각 사용자에 대해 상위 3개의 하차 지역 추천 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc41aecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 305:==================================================>(1990 + 2) / 2000]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   148|[{1, 84.120605}, ...|\n",
      "|   243|[{44, 136.12622},...|\n",
      "|    31|[{1, 156.18678}, ...|\n",
      "|    85|[{1, 99.85684}, {...|\n",
      "|   137|[{84, 94.54001}, ...|\n",
      "|   251|[{189, 2027.7919}...|\n",
      "|    65|[{265, 94.21752},...|\n",
      "|    53|[{189, 221.17395}...|\n",
      "|   255|[{1, 96.72472}, {...|\n",
      "|   133|[{1, 97.52325}, {...|\n",
      "|    78|[{84, 128.37975},...|\n",
      "|   108|[{1, 102.3983}, {...|\n",
      "|   155|[{1, 119.1133}, {...|\n",
      "|    34|[{1, 91.01179}, {...|\n",
      "|   193|[{5, 107.21838}, ...|\n",
      "|   211|[{204, 96.69918},...|\n",
      "|   101|[{99, 151.36998},...|\n",
      "|   115|[{207, 129.58487}...|\n",
      "|   126|[{189, 208.01349}...|\n",
      "|    81|[{44, 152.52078},...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 추천 결과 출력\n",
    "recommendations.show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "132f244d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(itemId=1, rating=84.12060546875),\n",
       " Row(itemId=84, rating=84.02555847167969),\n",
       " Row(itemId=265, rating=78.3370132446289),\n",
       " Row(itemId=5, rating=74.26792907714844),\n",
       " Row(itemId=109, rating=72.0291748046875),\n",
       " Row(itemId=201, rating=69.0174789428711),\n",
       " Row(itemId=204, rating=68.70468139648438),\n",
       " Row(itemId=86, rating=67.70645141601562),\n",
       " Row(itemId=176, rating=67.1243667602539),\n",
       " Row(itemId=101, rating=66.43974304199219)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_list = recommendations.collect()[0].recommendations\n",
    "location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6526065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|itemId|           rating|\n",
      "+------+-----------------+\n",
      "|     1|   84.12060546875|\n",
      "|    84|84.02555847167969|\n",
      "|   265| 78.3370132446289|\n",
      "|     5|74.26792907714844|\n",
      "|   109| 72.0291748046875|\n",
      "|   201| 69.0174789428711|\n",
      "|   204|68.70468139648438|\n",
      "|    86|67.70645141601562|\n",
      "|   176| 67.1243667602539|\n",
      "|   101|66.43974304199219|\n",
      "+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_df = spark.createDataFrame(location_list)\n",
    "rec_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af069978",
   "metadata": {},
   "source": [
    "## df join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b57a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임시 뷰로 등록\n",
    "rec_df.createOrReplaceTempView('recommend')\n",
    "zone_df.createOrReplaceTempView('zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37265bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|itemId|           rating|\n",
      "+------+-----------------+\n",
      "|     1|   84.12060546875|\n",
      "|    84|84.02555847167969|\n",
      "|   265| 78.3370132446289|\n",
      "+------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+----------+-------+--------------------+------------+\n",
      "|LocationID|Borough|                Zone|service_zone|\n",
      "+----------+-------+--------------------+------------+\n",
      "|         1|    EWR|      Newark Airport|         EWR|\n",
      "|         2| Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|  Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "+----------+-------+--------------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_df.show(3)\n",
    "zone_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "715ce809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+\n",
      "|         pickup_zone|        dropoff_zone|           rating|\n",
      "+--------------------+--------------------+-----------------+\n",
      "|      Newark Airport|      Newark Airport|   84.12060546875|\n",
      "|Eltingville/Annad...|Eltingville/Annad...|84.02555847167969|\n",
      "|                  NA|                  NA| 78.3370132446289|\n",
      "|       Arden Heights|       Arden Heights|74.26792907714844|\n",
      "|         Great Kills|         Great Kills| 72.0291748046875|\n",
      "|       Rockaway Park|       Rockaway Park| 69.0174789428711|\n",
      "|   Rossville/Woodrow|   Rossville/Woodrow|68.70468139648438|\n",
      "|        Far Rockaway|        Far Rockaway|67.70645141601562|\n",
      "|             Oakwood|             Oakwood| 67.1243667602539|\n",
      "|           Glen Oaks|           Glen Oaks|66.43974304199219|\n",
      "+--------------------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT \n",
    "    pz.Zone AS pickup_zone,\n",
    "    dz.Zone AS dropoff_zone,\n",
    "    t.rating\n",
    "\n",
    "FROM recommend t\n",
    "\n",
    "LEFT JOIN zone pz ON t.itemId = pz.LocationID  -- 승차 지역(PULocationID) 조인\n",
    "LEFT JOIN zone dz ON t.itemId = dz.LocationID  -- 하차 지역(DOLocationID) 조인\n",
    "'''\n",
    "recommended = spark.sql(query)\n",
    "recommended.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c99f012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9800483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark_start",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
