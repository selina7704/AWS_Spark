{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9980c6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/13 10:19:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-2-110.ap-northeast-3.compute.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>241212_02_MLlib_Regression</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fec3bac4310>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"241212_02_MLlib_Regression\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b7f9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\",'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load(\"data/house_train.csv\")\n",
    "\n",
    "test_df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\",'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load(\"data/house_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3138e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- MSSubClass: integer (nullable = true)\n",
      " |-- MSZoning: string (nullable = true)\n",
      " |-- LotFrontage: string (nullable = true)\n",
      " |-- LotArea: integer (nullable = true)\n",
      " |-- Street: string (nullable = true)\n",
      " |-- Alley: string (nullable = true)\n",
      " |-- LotShape: string (nullable = true)\n",
      " |-- LandContour: string (nullable = true)\n",
      " |-- Utilities: string (nullable = true)\n",
      " |-- LotConfig: string (nullable = true)\n",
      " |-- LandSlope: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Condition1: string (nullable = true)\n",
      " |-- Condition2: string (nullable = true)\n",
      " |-- BldgType: string (nullable = true)\n",
      " |-- HouseStyle: string (nullable = true)\n",
      " |-- OverallQual: integer (nullable = true)\n",
      " |-- OverallCond: integer (nullable = true)\n",
      " |-- YearBuilt: integer (nullable = true)\n",
      " |-- YearRemodAdd: integer (nullable = true)\n",
      " |-- RoofStyle: string (nullable = true)\n",
      " |-- RoofMatl: string (nullable = true)\n",
      " |-- Exterior1st: string (nullable = true)\n",
      " |-- Exterior2nd: string (nullable = true)\n",
      " |-- MasVnrType: string (nullable = true)\n",
      " |-- MasVnrArea: string (nullable = true)\n",
      " |-- ExterQual: string (nullable = true)\n",
      " |-- ExterCond: string (nullable = true)\n",
      " |-- Foundation: string (nullable = true)\n",
      " |-- BsmtQual: string (nullable = true)\n",
      " |-- BsmtCond: string (nullable = true)\n",
      " |-- BsmtExposure: string (nullable = true)\n",
      " |-- BsmtFinType1: string (nullable = true)\n",
      " |-- BsmtFinSF1: integer (nullable = true)\n",
      " |-- BsmtFinType2: string (nullable = true)\n",
      " |-- BsmtFinSF2: integer (nullable = true)\n",
      " |-- BsmtUnfSF: integer (nullable = true)\n",
      " |-- TotalBsmtSF: integer (nullable = true)\n",
      " |-- Heating: string (nullable = true)\n",
      " |-- HeatingQC: string (nullable = true)\n",
      " |-- CentralAir: string (nullable = true)\n",
      " |-- Electrical: string (nullable = true)\n",
      " |-- 1stFlrSF: integer (nullable = true)\n",
      " |-- 2ndFlrSF: integer (nullable = true)\n",
      " |-- LowQualFinSF: integer (nullable = true)\n",
      " |-- GrLivArea: integer (nullable = true)\n",
      " |-- BsmtFullBath: integer (nullable = true)\n",
      " |-- BsmtHalfBath: integer (nullable = true)\n",
      " |-- FullBath: integer (nullable = true)\n",
      " |-- HalfBath: integer (nullable = true)\n",
      " |-- BedroomAbvGr: integer (nullable = true)\n",
      " |-- KitchenAbvGr: integer (nullable = true)\n",
      " |-- KitchenQual: string (nullable = true)\n",
      " |-- TotRmsAbvGrd: integer (nullable = true)\n",
      " |-- Functional: string (nullable = true)\n",
      " |-- Fireplaces: integer (nullable = true)\n",
      " |-- FireplaceQu: string (nullable = true)\n",
      " |-- GarageType: string (nullable = true)\n",
      " |-- GarageYrBlt: string (nullable = true)\n",
      " |-- GarageFinish: string (nullable = true)\n",
      " |-- GarageCars: integer (nullable = true)\n",
      " |-- GarageArea: integer (nullable = true)\n",
      " |-- GarageQual: string (nullable = true)\n",
      " |-- GarageCond: string (nullable = true)\n",
      " |-- PavedDrive: string (nullable = true)\n",
      " |-- WoodDeckSF: integer (nullable = true)\n",
      " |-- OpenPorchSF: integer (nullable = true)\n",
      " |-- EnclosedPorch: integer (nullable = true)\n",
      " |-- 3SsnPorch: integer (nullable = true)\n",
      " |-- ScreenPorch: integer (nullable = true)\n",
      " |-- PoolArea: integer (nullable = true)\n",
      " |-- PoolQC: string (nullable = true)\n",
      " |-- Fence: string (nullable = true)\n",
      " |-- MiscFeature: string (nullable = true)\n",
      " |-- MiscVal: integer (nullable = true)\n",
      " |-- MoSold: integer (nullable = true)\n",
      " |-- YrSold: integer (nullable = true)\n",
      " |-- SaleType: string (nullable = true)\n",
      " |-- SaleCondition: string (nullable = true)\n",
      " |-- SalePrice: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63f56941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- MSSubClass: integer (nullable = true)\n",
      " |-- MSZoning: string (nullable = true)\n",
      " |-- LotFrontage: string (nullable = true)\n",
      " |-- LotArea: integer (nullable = true)\n",
      " |-- Street: string (nullable = true)\n",
      " |-- Alley: string (nullable = true)\n",
      " |-- LotShape: string (nullable = true)\n",
      " |-- LandContour: string (nullable = true)\n",
      " |-- Utilities: string (nullable = true)\n",
      " |-- LotConfig: string (nullable = true)\n",
      " |-- LandSlope: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Condition1: string (nullable = true)\n",
      " |-- Condition2: string (nullable = true)\n",
      " |-- BldgType: string (nullable = true)\n",
      " |-- HouseStyle: string (nullable = true)\n",
      " |-- OverallQual: integer (nullable = true)\n",
      " |-- OverallCond: integer (nullable = true)\n",
      " |-- YearBuilt: integer (nullable = true)\n",
      " |-- YearRemodAdd: integer (nullable = true)\n",
      " |-- RoofStyle: string (nullable = true)\n",
      " |-- RoofMatl: string (nullable = true)\n",
      " |-- Exterior1st: string (nullable = true)\n",
      " |-- Exterior2nd: string (nullable = true)\n",
      " |-- MasVnrType: string (nullable = true)\n",
      " |-- MasVnrArea: string (nullable = true)\n",
      " |-- ExterQual: string (nullable = true)\n",
      " |-- ExterCond: string (nullable = true)\n",
      " |-- Foundation: string (nullable = true)\n",
      " |-- BsmtQual: string (nullable = true)\n",
      " |-- BsmtCond: string (nullable = true)\n",
      " |-- BsmtExposure: string (nullable = true)\n",
      " |-- BsmtFinType1: string (nullable = true)\n",
      " |-- BsmtFinSF1: string (nullable = true)\n",
      " |-- BsmtFinType2: string (nullable = true)\n",
      " |-- BsmtFinSF2: string (nullable = true)\n",
      " |-- BsmtUnfSF: string (nullable = true)\n",
      " |-- TotalBsmtSF: string (nullable = true)\n",
      " |-- Heating: string (nullable = true)\n",
      " |-- HeatingQC: string (nullable = true)\n",
      " |-- CentralAir: string (nullable = true)\n",
      " |-- Electrical: string (nullable = true)\n",
      " |-- 1stFlrSF: integer (nullable = true)\n",
      " |-- 2ndFlrSF: integer (nullable = true)\n",
      " |-- LowQualFinSF: integer (nullable = true)\n",
      " |-- GrLivArea: integer (nullable = true)\n",
      " |-- BsmtFullBath: string (nullable = true)\n",
      " |-- BsmtHalfBath: string (nullable = true)\n",
      " |-- FullBath: integer (nullable = true)\n",
      " |-- HalfBath: integer (nullable = true)\n",
      " |-- BedroomAbvGr: integer (nullable = true)\n",
      " |-- KitchenAbvGr: integer (nullable = true)\n",
      " |-- KitchenQual: string (nullable = true)\n",
      " |-- TotRmsAbvGrd: integer (nullable = true)\n",
      " |-- Functional: string (nullable = true)\n",
      " |-- Fireplaces: integer (nullable = true)\n",
      " |-- FireplaceQu: string (nullable = true)\n",
      " |-- GarageType: string (nullable = true)\n",
      " |-- GarageYrBlt: string (nullable = true)\n",
      " |-- GarageFinish: string (nullable = true)\n",
      " |-- GarageCars: string (nullable = true)\n",
      " |-- GarageArea: string (nullable = true)\n",
      " |-- GarageQual: string (nullable = true)\n",
      " |-- GarageCond: string (nullable = true)\n",
      " |-- PavedDrive: string (nullable = true)\n",
      " |-- WoodDeckSF: integer (nullable = true)\n",
      " |-- OpenPorchSF: integer (nullable = true)\n",
      " |-- EnclosedPorch: integer (nullable = true)\n",
      " |-- 3SsnPorch: integer (nullable = true)\n",
      " |-- ScreenPorch: integer (nullable = true)\n",
      " |-- PoolArea: integer (nullable = true)\n",
      " |-- PoolQC: string (nullable = true)\n",
      " |-- Fence: string (nullable = true)\n",
      " |-- MiscFeature: string (nullable = true)\n",
      " |-- MiscVal: integer (nullable = true)\n",
      " |-- MoSold: integer (nullable = true)\n",
      " |-- YrSold: integer (nullable = true)\n",
      " |-- SaleType: string (nullable = true)\n",
      " |-- SaleCondition: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae1b56d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/13 10:19:12 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+-----------+-------+------+-----+--------+-----------+---------+---------+---------+------------+----------+----------+--------+----------+-----------+-----------+---------+------------+---------+--------+-----------+-----------+----------+----------+---------+---------+----------+--------+--------+------------+------------+----------+------------+----------+---------+-----------+-------+---------+----------+----------+--------+--------+------------+---------+------------+------------+--------+--------+------------+------------+-----------+------------+----------+----------+-----------+----------+-----------+------------+----------+----------+----------+----------+----------+----------+-----------+-------------+---------+-----------+--------+------+-----+-----------+-------+------+------+--------+-------------+---------+\n",
      "| Id|MSSubClass|MSZoning|LotFrontage|LotArea|Street|Alley|LotShape|LandContour|Utilities|LotConfig|LandSlope|Neighborhood|Condition1|Condition2|BldgType|HouseStyle|OverallQual|OverallCond|YearBuilt|YearRemodAdd|RoofStyle|RoofMatl|Exterior1st|Exterior2nd|MasVnrType|MasVnrArea|ExterQual|ExterCond|Foundation|BsmtQual|BsmtCond|BsmtExposure|BsmtFinType1|BsmtFinSF1|BsmtFinType2|BsmtFinSF2|BsmtUnfSF|TotalBsmtSF|Heating|HeatingQC|CentralAir|Electrical|1stFlrSF|2ndFlrSF|LowQualFinSF|GrLivArea|BsmtFullBath|BsmtHalfBath|FullBath|HalfBath|BedroomAbvGr|KitchenAbvGr|KitchenQual|TotRmsAbvGrd|Functional|Fireplaces|FireplaceQu|GarageType|GarageYrBlt|GarageFinish|GarageCars|GarageArea|GarageQual|GarageCond|PavedDrive|WoodDeckSF|OpenPorchSF|EnclosedPorch|3SsnPorch|ScreenPorch|PoolArea|PoolQC|Fence|MiscFeature|MiscVal|MoSold|YrSold|SaleType|SaleCondition|SalePrice|\n",
      "+---+----------+--------+-----------+-------+------+-----+--------+-----------+---------+---------+---------+------------+----------+----------+--------+----------+-----------+-----------+---------+------------+---------+--------+-----------+-----------+----------+----------+---------+---------+----------+--------+--------+------------+------------+----------+------------+----------+---------+-----------+-------+---------+----------+----------+--------+--------+------------+---------+------------+------------+--------+--------+------------+------------+-----------+------------+----------+----------+-----------+----------+-----------+------------+----------+----------+----------+----------+----------+----------+-----------+-------------+---------+-----------+--------+------+-----+-----------+-------+------+------+--------+-------------+---------+\n",
      "|  1|        60|      RL|         65|   8450|  Pave|   NA|     Reg|        Lvl|   AllPub|   Inside|      Gtl|     CollgCr|      Norm|      Norm|    1Fam|    2Story|          7|          5|     2003|        2003|    Gable| CompShg|    VinylSd|    VinylSd|   BrkFace|       196|       Gd|       TA|     PConc|      Gd|      TA|          No|         GLQ|       706|         Unf|         0|      150|        856|   GasA|       Ex|         Y|     SBrkr|     856|     854|           0|     1710|           1|           0|       2|       1|           3|           1|         Gd|           8|       Typ|         0|         NA|    Attchd|       2003|         RFn|         2|       548|        TA|        TA|         Y|         0|         61|            0|        0|          0|       0|    NA|   NA|         NA|      0|     2|  2008|      WD|       Normal|   208500|\n",
      "|  2|        20|      RL|         80|   9600|  Pave|   NA|     Reg|        Lvl|   AllPub|      FR2|      Gtl|     Veenker|     Feedr|      Norm|    1Fam|    1Story|          6|          8|     1976|        1976|    Gable| CompShg|    MetalSd|    MetalSd|      None|         0|       TA|       TA|    CBlock|      Gd|      TA|          Gd|         ALQ|       978|         Unf|         0|      284|       1262|   GasA|       Ex|         Y|     SBrkr|    1262|       0|           0|     1262|           0|           1|       2|       0|           3|           1|         TA|           6|       Typ|         1|         TA|    Attchd|       1976|         RFn|         2|       460|        TA|        TA|         Y|       298|          0|            0|        0|          0|       0|    NA|   NA|         NA|      0|     5|  2007|      WD|       Normal|   181500|\n",
      "|  3|        60|      RL|         68|  11250|  Pave|   NA|     IR1|        Lvl|   AllPub|   Inside|      Gtl|     CollgCr|      Norm|      Norm|    1Fam|    2Story|          7|          5|     2001|        2002|    Gable| CompShg|    VinylSd|    VinylSd|   BrkFace|       162|       Gd|       TA|     PConc|      Gd|      TA|          Mn|         GLQ|       486|         Unf|         0|      434|        920|   GasA|       Ex|         Y|     SBrkr|     920|     866|           0|     1786|           1|           0|       2|       1|           3|           1|         Gd|           6|       Typ|         1|         TA|    Attchd|       2001|         RFn|         2|       608|        TA|        TA|         Y|         0|         42|            0|        0|          0|       0|    NA|   NA|         NA|      0|     9|  2008|      WD|       Normal|   223500|\n",
      "|  4|        70|      RL|         60|   9550|  Pave|   NA|     IR1|        Lvl|   AllPub|   Corner|      Gtl|     Crawfor|      Norm|      Norm|    1Fam|    2Story|          7|          5|     1915|        1970|    Gable| CompShg|    Wd Sdng|    Wd Shng|      None|         0|       TA|       TA|    BrkTil|      TA|      Gd|          No|         ALQ|       216|         Unf|         0|      540|        756|   GasA|       Gd|         Y|     SBrkr|     961|     756|           0|     1717|           1|           0|       1|       0|           3|           1|         Gd|           7|       Typ|         1|         Gd|    Detchd|       1998|         Unf|         3|       642|        TA|        TA|         Y|         0|         35|          272|        0|          0|       0|    NA|   NA|         NA|      0|     2|  2006|      WD|      Abnorml|   140000|\n",
      "|  5|        60|      RL|         84|  14260|  Pave|   NA|     IR1|        Lvl|   AllPub|      FR2|      Gtl|     NoRidge|      Norm|      Norm|    1Fam|    2Story|          8|          5|     2000|        2000|    Gable| CompShg|    VinylSd|    VinylSd|   BrkFace|       350|       Gd|       TA|     PConc|      Gd|      TA|          Av|         GLQ|       655|         Unf|         0|      490|       1145|   GasA|       Ex|         Y|     SBrkr|    1145|    1053|           0|     2198|           1|           0|       2|       1|           4|           1|         Gd|           9|       Typ|         1|         TA|    Attchd|       2000|         RFn|         3|       836|        TA|        TA|         Y|       192|         84|            0|        0|          0|       0|    NA|   NA|         NA|      0|    12|  2008|      WD|       Normal|   250000|\n",
      "|  6|        50|      RL|         85|  14115|  Pave|   NA|     IR1|        Lvl|   AllPub|   Inside|      Gtl|     Mitchel|      Norm|      Norm|    1Fam|    1.5Fin|          5|          5|     1993|        1995|    Gable| CompShg|    VinylSd|    VinylSd|      None|         0|       TA|       TA|      Wood|      Gd|      TA|          No|         GLQ|       732|         Unf|         0|       64|        796|   GasA|       Ex|         Y|     SBrkr|     796|     566|           0|     1362|           1|           0|       1|       1|           1|           1|         TA|           5|       Typ|         0|         NA|    Attchd|       1993|         Unf|         2|       480|        TA|        TA|         Y|        40|         30|            0|      320|          0|       0|    NA|MnPrv|       Shed|    700|    10|  2009|      WD|       Normal|   143000|\n",
      "|  7|        20|      RL|         75|  10084|  Pave|   NA|     Reg|        Lvl|   AllPub|   Inside|      Gtl|     Somerst|      Norm|      Norm|    1Fam|    1Story|          8|          5|     2004|        2005|    Gable| CompShg|    VinylSd|    VinylSd|     Stone|       186|       Gd|       TA|     PConc|      Ex|      TA|          Av|         GLQ|      1369|         Unf|         0|      317|       1686|   GasA|       Ex|         Y|     SBrkr|    1694|       0|           0|     1694|           1|           0|       2|       0|           3|           1|         Gd|           7|       Typ|         1|         Gd|    Attchd|       2004|         RFn|         2|       636|        TA|        TA|         Y|       255|         57|            0|        0|          0|       0|    NA|   NA|         NA|      0|     8|  2007|      WD|       Normal|   307000|\n",
      "|  8|        60|      RL|         NA|  10382|  Pave|   NA|     IR1|        Lvl|   AllPub|   Corner|      Gtl|      NWAmes|      PosN|      Norm|    1Fam|    2Story|          7|          6|     1973|        1973|    Gable| CompShg|    HdBoard|    HdBoard|     Stone|       240|       TA|       TA|    CBlock|      Gd|      TA|          Mn|         ALQ|       859|         BLQ|        32|      216|       1107|   GasA|       Ex|         Y|     SBrkr|    1107|     983|           0|     2090|           1|           0|       2|       1|           3|           1|         TA|           7|       Typ|         2|         TA|    Attchd|       1973|         RFn|         2|       484|        TA|        TA|         Y|       235|        204|          228|        0|          0|       0|    NA|   NA|       Shed|    350|    11|  2009|      WD|       Normal|   200000|\n",
      "|  9|        50|      RM|         51|   6120|  Pave|   NA|     Reg|        Lvl|   AllPub|   Inside|      Gtl|     OldTown|    Artery|      Norm|    1Fam|    1.5Fin|          7|          5|     1931|        1950|    Gable| CompShg|    BrkFace|    Wd Shng|      None|         0|       TA|       TA|    BrkTil|      TA|      TA|          No|         Unf|         0|         Unf|         0|      952|        952|   GasA|       Gd|         Y|     FuseF|    1022|     752|           0|     1774|           0|           0|       2|       0|           2|           2|         TA|           8|      Min1|         2|         TA|    Detchd|       1931|         Unf|         2|       468|        Fa|        TA|         Y|        90|          0|          205|        0|          0|       0|    NA|   NA|         NA|      0|     4|  2008|      WD|      Abnorml|   129900|\n",
      "| 10|       190|      RL|         50|   7420|  Pave|   NA|     Reg|        Lvl|   AllPub|   Corner|      Gtl|     BrkSide|    Artery|    Artery|  2fmCon|    1.5Unf|          5|          6|     1939|        1950|    Gable| CompShg|    MetalSd|    MetalSd|      None|         0|       TA|       TA|    BrkTil|      TA|      TA|          No|         GLQ|       851|         Unf|         0|      140|        991|   GasA|       Ex|         Y|     SBrkr|    1077|       0|           0|     1077|           1|           0|       1|       0|           2|           2|         TA|           5|       Typ|         2|         TA|    Attchd|       1939|         RFn|         1|       205|        Gd|        TA|         Y|         0|          4|            0|        0|          0|       0|    NA|   NA|         NA|      0|     1|  2008|      WD|       Normal|   118000|\n",
      "| 11|        20|      RL|         70|  11200|  Pave|   NA|     Reg|        Lvl|   AllPub|   Inside|      Gtl|      Sawyer|      Norm|      Norm|    1Fam|    1Story|          5|          5|     1965|        1965|      Hip| CompShg|    HdBoard|    HdBoard|      None|         0|       TA|       TA|    CBlock|      TA|      TA|          No|         Rec|       906|         Unf|         0|      134|       1040|   GasA|       Ex|         Y|     SBrkr|    1040|       0|           0|     1040|           1|           0|       1|       0|           3|           1|         TA|           5|       Typ|         0|         NA|    Detchd|       1965|         Unf|         1|       384|        TA|        TA|         Y|         0|          0|            0|        0|          0|       0|    NA|   NA|         NA|      0|     2|  2008|      WD|       Normal|   129500|\n",
      "| 12|        60|      RL|         85|  11924|  Pave|   NA|     IR1|        Lvl|   AllPub|   Inside|      Gtl|     NridgHt|      Norm|      Norm|    1Fam|    2Story|          9|          5|     2005|        2006|      Hip| CompShg|    WdShing|    Wd Shng|     Stone|       286|       Ex|       TA|     PConc|      Ex|      TA|          No|         GLQ|       998|         Unf|         0|      177|       1175|   GasA|       Ex|         Y|     SBrkr|    1182|    1142|           0|     2324|           1|           0|       3|       0|           4|           1|         Ex|          11|       Typ|         2|         Gd|   BuiltIn|       2005|         Fin|         3|       736|        TA|        TA|         Y|       147|         21|            0|        0|          0|       0|    NA|   NA|         NA|      0|     7|  2006|     New|      Partial|   345000|\n",
      "| 13|        20|      RL|         NA|  12968|  Pave|   NA|     IR2|        Lvl|   AllPub|   Inside|      Gtl|      Sawyer|      Norm|      Norm|    1Fam|    1Story|          5|          6|     1962|        1962|      Hip| CompShg|    HdBoard|    Plywood|      None|         0|       TA|       TA|    CBlock|      TA|      TA|          No|         ALQ|       737|         Unf|         0|      175|        912|   GasA|       TA|         Y|     SBrkr|     912|       0|           0|      912|           1|           0|       1|       0|           2|           1|         TA|           4|       Typ|         0|         NA|    Detchd|       1962|         Unf|         1|       352|        TA|        TA|         Y|       140|          0|            0|        0|        176|       0|    NA|   NA|         NA|      0|     9|  2008|      WD|       Normal|   144000|\n",
      "| 14|        20|      RL|         91|  10652|  Pave|   NA|     IR1|        Lvl|   AllPub|   Inside|      Gtl|     CollgCr|      Norm|      Norm|    1Fam|    1Story|          7|          5|     2006|        2007|    Gable| CompShg|    VinylSd|    VinylSd|     Stone|       306|       Gd|       TA|     PConc|      Gd|      TA|          Av|         Unf|         0|         Unf|         0|     1494|       1494|   GasA|       Ex|         Y|     SBrkr|    1494|       0|           0|     1494|           0|           0|       2|       0|           3|           1|         Gd|           7|       Typ|         1|         Gd|    Attchd|       2006|         RFn|         3|       840|        TA|        TA|         Y|       160|         33|            0|        0|          0|       0|    NA|   NA|         NA|      0|     8|  2007|     New|      Partial|   279500|\n",
      "| 15|        20|      RL|         NA|  10920|  Pave|   NA|     IR1|        Lvl|   AllPub|   Corner|      Gtl|       NAmes|      Norm|      Norm|    1Fam|    1Story|          6|          5|     1960|        1960|      Hip| CompShg|    MetalSd|    MetalSd|   BrkFace|       212|       TA|       TA|    CBlock|      TA|      TA|          No|         BLQ|       733|         Unf|         0|      520|       1253|   GasA|       TA|         Y|     SBrkr|    1253|       0|           0|     1253|           1|           0|       1|       1|           2|           1|         TA|           5|       Typ|         1|         Fa|    Attchd|       1960|         RFn|         1|       352|        TA|        TA|         Y|         0|        213|          176|        0|          0|       0|    NA| GdWo|         NA|      0|     5|  2008|      WD|       Normal|   157000|\n",
      "| 16|        45|      RM|         51|   6120|  Pave|   NA|     Reg|        Lvl|   AllPub|   Corner|      Gtl|     BrkSide|      Norm|      Norm|    1Fam|    1.5Unf|          7|          8|     1929|        2001|    Gable| CompShg|    Wd Sdng|    Wd Sdng|      None|         0|       TA|       TA|    BrkTil|      TA|      TA|          No|         Unf|         0|         Unf|         0|      832|        832|   GasA|       Ex|         Y|     FuseA|     854|       0|           0|      854|           0|           0|       1|       0|           2|           1|         TA|           5|       Typ|         0|         NA|    Detchd|       1991|         Unf|         2|       576|        TA|        TA|         Y|        48|        112|            0|        0|          0|       0|    NA|GdPrv|         NA|      0|     7|  2007|      WD|       Normal|   132000|\n",
      "| 17|        20|      RL|         NA|  11241|  Pave|   NA|     IR1|        Lvl|   AllPub|  CulDSac|      Gtl|       NAmes|      Norm|      Norm|    1Fam|    1Story|          6|          7|     1970|        1970|    Gable| CompShg|    Wd Sdng|    Wd Sdng|   BrkFace|       180|       TA|       TA|    CBlock|      TA|      TA|          No|         ALQ|       578|         Unf|         0|      426|       1004|   GasA|       Ex|         Y|     SBrkr|    1004|       0|           0|     1004|           1|           0|       1|       0|           2|           1|         TA|           5|       Typ|         1|         TA|    Attchd|       1970|         Fin|         2|       480|        TA|        TA|         Y|         0|          0|            0|        0|          0|       0|    NA|   NA|       Shed|    700|     3|  2010|      WD|       Normal|   149000|\n",
      "| 18|        90|      RL|         72|  10791|  Pave|   NA|     Reg|        Lvl|   AllPub|   Inside|      Gtl|      Sawyer|      Norm|      Norm|  Duplex|    1Story|          4|          5|     1967|        1967|    Gable| CompShg|    MetalSd|    MetalSd|      None|         0|       TA|       TA|      Slab|      NA|      NA|          NA|          NA|         0|          NA|         0|        0|          0|   GasA|       TA|         Y|     SBrkr|    1296|       0|           0|     1296|           0|           0|       2|       0|           2|           2|         TA|           6|       Typ|         0|         NA|   CarPort|       1967|         Unf|         2|       516|        TA|        TA|         Y|         0|          0|            0|        0|          0|       0|    NA|   NA|       Shed|    500|    10|  2006|      WD|       Normal|    90000|\n",
      "| 19|        20|      RL|         66|  13695|  Pave|   NA|     Reg|        Lvl|   AllPub|   Inside|      Gtl|     SawyerW|      RRAe|      Norm|    1Fam|    1Story|          5|          5|     2004|        2004|    Gable| CompShg|    VinylSd|    VinylSd|      None|         0|       TA|       TA|     PConc|      TA|      TA|          No|         GLQ|       646|         Unf|         0|      468|       1114|   GasA|       Ex|         Y|     SBrkr|    1114|       0|           0|     1114|           1|           0|       1|       1|           3|           1|         Gd|           6|       Typ|         0|         NA|    Detchd|       2004|         Unf|         2|       576|        TA|        TA|         Y|         0|        102|            0|        0|          0|       0|    NA|   NA|         NA|      0|     6|  2008|      WD|       Normal|   159000|\n",
      "| 20|        20|      RL|         70|   7560|  Pave|   NA|     Reg|        Lvl|   AllPub|   Inside|      Gtl|       NAmes|      Norm|      Norm|    1Fam|    1Story|          5|          6|     1958|        1965|      Hip| CompShg|    BrkFace|    Plywood|      None|         0|       TA|       TA|    CBlock|      TA|      TA|          No|         LwQ|       504|         Unf|         0|      525|       1029|   GasA|       TA|         Y|     SBrkr|    1339|       0|           0|     1339|           0|           0|       1|       0|           3|           1|         TA|           6|      Min1|         0|         NA|    Attchd|       1958|         Unf|         1|       294|        TA|        TA|         Y|         0|          0|            0|        0|          0|       0|    NA|MnPrv|         NA|      0|     5|  2009|     COD|      Abnorml|   139000|\n",
      "+---+----------+--------+-----------+-------+------+-----+--------+-----------+---------+---------+---------+------------+----------+----------+--------+----------+-----------+-----------+---------+------------+---------+--------+-----------+-----------+----------+----------+---------+---------+----------+--------+--------+------------+------------+----------+------------+----------+---------+-----------+-------+---------+----------+----------+--------+--------+------------+---------+------------+------------+--------+--------+------------+------------+-----------+------------+----------+----------+-----------+----------+-----------+------------+----------+----------+----------+----------+----------+----------+-----------+-------------+---------+-----------+--------+------+-----+-----------+-------+------+------+--------+-------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+--------+-----------+-------+------+-----+--------+-----------+---------+---------+---------+------------+----------+----------+--------+----------+-----------+-----------+---------+------------+---------+--------+-----------+-----------+----------+----------+---------+---------+----------+--------+--------+------------+------------+----------+------------+----------+---------+-----------+-------+---------+----------+----------+--------+--------+------------+---------+------------+------------+--------+--------+------------+------------+-----------+------------+----------+----------+-----------+----------+-----------+------------+----------+----------+----------+----------+----------+----------+-----------+-------------+---------+-----------+--------+------+-----+-----------+-------+------+------+--------+-------------+\n",
      "|  Id|MSSubClass|MSZoning|LotFrontage|LotArea|Street|Alley|LotShape|LandContour|Utilities|LotConfig|LandSlope|Neighborhood|Condition1|Condition2|BldgType|HouseStyle|OverallQual|OverallCond|YearBuilt|YearRemodAdd|RoofStyle|RoofMatl|Exterior1st|Exterior2nd|MasVnrType|MasVnrArea|ExterQual|ExterCond|Foundation|BsmtQual|BsmtCond|BsmtExposure|BsmtFinType1|BsmtFinSF1|BsmtFinType2|BsmtFinSF2|BsmtUnfSF|TotalBsmtSF|Heating|HeatingQC|CentralAir|Electrical|1stFlrSF|2ndFlrSF|LowQualFinSF|GrLivArea|BsmtFullBath|BsmtHalfBath|FullBath|HalfBath|BedroomAbvGr|KitchenAbvGr|KitchenQual|TotRmsAbvGrd|Functional|Fireplaces|FireplaceQu|GarageType|GarageYrBlt|GarageFinish|GarageCars|GarageArea|GarageQual|GarageCond|PavedDrive|WoodDeckSF|OpenPorchSF|EnclosedPorch|3SsnPorch|ScreenPorch|PoolArea|PoolQC|Fence|MiscFeature|MiscVal|MoSold|YrSold|SaleType|SaleCondition|\n",
      "+----+----------+--------+-----------+-------+------+-----+--------+-----------+---------+---------+---------+------------+----------+----------+--------+----------+-----------+-----------+---------+------------+---------+--------+-----------+-----------+----------+----------+---------+---------+----------+--------+--------+------------+------------+----------+------------+----------+---------+-----------+-------+---------+----------+----------+--------+--------+------------+---------+------------+------------+--------+--------+------------+------------+-----------+------------+----------+----------+-----------+----------+-----------+------------+----------+----------+----------+----------+----------+----------+-----------+-------------+---------+-----------+--------+------+-----+-----------+-------+------+------+--------+-------------+\n",
      "|1461|        20|      RH|         80|  11622|  Pave|   NA|     Reg|        Lvl|   AllPub|   Inside|      Gtl|       NAmes|     Feedr|      Norm|    1Fam|    1Story|          5|          6|     1961|        1961|    Gable| CompShg|    VinylSd|    VinylSd|      None|         0|       TA|       TA|    CBlock|      TA|      TA|          No|         Rec|       468|         LwQ|       144|      270|        882|   GasA|       TA|         Y|     SBrkr|     896|       0|           0|      896|           0|           0|       1|       0|           2|           1|         TA|           5|       Typ|         0|         NA|    Attchd|       1961|         Unf|         1|       730|        TA|        TA|         Y|       140|          0|            0|        0|        120|       0|    NA|MnPrv|         NA|      0|     6|  2010|      WD|       Normal|\n",
      "|1462|        20|      RL|         81|  14267|  Pave|   NA|     IR1|        Lvl|   AllPub|   Corner|      Gtl|       NAmes|      Norm|      Norm|    1Fam|    1Story|          6|          6|     1958|        1958|      Hip| CompShg|    Wd Sdng|    Wd Sdng|   BrkFace|       108|       TA|       TA|    CBlock|      TA|      TA|          No|         ALQ|       923|         Unf|         0|      406|       1329|   GasA|       TA|         Y|     SBrkr|    1329|       0|           0|     1329|           0|           0|       1|       1|           3|           1|         Gd|           6|       Typ|         0|         NA|    Attchd|       1958|         Unf|         1|       312|        TA|        TA|         Y|       393|         36|            0|        0|          0|       0|    NA|   NA|       Gar2|  12500|     6|  2010|      WD|       Normal|\n",
      "|1463|        60|      RL|         74|  13830|  Pave|   NA|     IR1|        Lvl|   AllPub|   Inside|      Gtl|     Gilbert|      Norm|      Norm|    1Fam|    2Story|          5|          5|     1997|        1998|    Gable| CompShg|    VinylSd|    VinylSd|      None|         0|       TA|       TA|     PConc|      Gd|      TA|          No|         GLQ|       791|         Unf|         0|      137|        928|   GasA|       Gd|         Y|     SBrkr|     928|     701|           0|     1629|           0|           0|       2|       1|           3|           1|         TA|           6|       Typ|         1|         TA|    Attchd|       1997|         Fin|         2|       482|        TA|        TA|         Y|       212|         34|            0|        0|          0|       0|    NA|MnPrv|         NA|      0|     3|  2010|      WD|       Normal|\n",
      "|1464|        60|      RL|         78|   9978|  Pave|   NA|     IR1|        Lvl|   AllPub|   Inside|      Gtl|     Gilbert|      Norm|      Norm|    1Fam|    2Story|          6|          6|     1998|        1998|    Gable| CompShg|    VinylSd|    VinylSd|   BrkFace|        20|       TA|       TA|     PConc|      TA|      TA|          No|         GLQ|       602|         Unf|         0|      324|        926|   GasA|       Ex|         Y|     SBrkr|     926|     678|           0|     1604|           0|           0|       2|       1|           3|           1|         Gd|           7|       Typ|         1|         Gd|    Attchd|       1998|         Fin|         2|       470|        TA|        TA|         Y|       360|         36|            0|        0|          0|       0|    NA|   NA|         NA|      0|     6|  2010|      WD|       Normal|\n",
      "|1465|       120|      RL|         43|   5005|  Pave|   NA|     IR1|        HLS|   AllPub|   Inside|      Gtl|     StoneBr|      Norm|      Norm|  TwnhsE|    1Story|          8|          5|     1992|        1992|    Gable| CompShg|    HdBoard|    HdBoard|      None|         0|       Gd|       TA|     PConc|      Gd|      TA|          No|         ALQ|       263|         Unf|         0|     1017|       1280|   GasA|       Ex|         Y|     SBrkr|    1280|       0|           0|     1280|           0|           0|       2|       0|           2|           1|         Gd|           5|       Typ|         0|         NA|    Attchd|       1992|         RFn|         2|       506|        TA|        TA|         Y|         0|         82|            0|        0|        144|       0|    NA|   NA|         NA|      0|     1|  2010|      WD|       Normal|\n",
      "|1466|        60|      RL|         75|  10000|  Pave|   NA|     IR1|        Lvl|   AllPub|   Corner|      Gtl|     Gilbert|      Norm|      Norm|    1Fam|    2Story|          6|          5|     1993|        1994|    Gable| CompShg|    HdBoard|    HdBoard|      None|         0|       TA|       TA|     PConc|      Gd|      TA|          No|         Unf|         0|         Unf|         0|      763|        763|   GasA|       Gd|         Y|     SBrkr|     763|     892|           0|     1655|           0|           0|       2|       1|           3|           1|         TA|           7|       Typ|         1|         TA|    Attchd|       1993|         Fin|         2|       440|        TA|        TA|         Y|       157|         84|            0|        0|          0|       0|    NA|   NA|         NA|      0|     4|  2010|      WD|       Normal|\n",
      "|1467|        20|      RL|         NA|   7980|  Pave|   NA|     IR1|        Lvl|   AllPub|   Inside|      Gtl|     Gilbert|      Norm|      Norm|    1Fam|    1Story|          6|          7|     1992|        2007|    Gable| CompShg|    HdBoard|    HdBoard|      None|         0|       TA|       Gd|     PConc|      Gd|      TA|          No|         ALQ|       935|         Unf|         0|      233|       1168|   GasA|       Ex|         Y|     SBrkr|    1187|       0|           0|     1187|           1|           0|       2|       0|           3|           1|         TA|           6|       Typ|         0|         NA|    Attchd|       1992|         Fin|         2|       420|        TA|        TA|         Y|       483|         21|            0|        0|          0|       0|    NA|GdPrv|       Shed|    500|     3|  2010|      WD|       Normal|\n",
      "|1468|        60|      RL|         63|   8402|  Pave|   NA|     IR1|        Lvl|   AllPub|   Inside|      Gtl|     Gilbert|      Norm|      Norm|    1Fam|    2Story|          6|          5|     1998|        1998|    Gable| CompShg|    VinylSd|    VinylSd|      None|         0|       TA|       TA|     PConc|      Gd|      TA|          No|         Unf|         0|         Unf|         0|      789|        789|   GasA|       Gd|         Y|     SBrkr|     789|     676|           0|     1465|           0|           0|       2|       1|           3|           1|         TA|           7|       Typ|         1|         Gd|    Attchd|       1998|         Fin|         2|       393|        TA|        TA|         Y|         0|         75|            0|        0|          0|       0|    NA|   NA|         NA|      0|     5|  2010|      WD|       Normal|\n",
      "|1469|        20|      RL|         85|  10176|  Pave|   NA|     Reg|        Lvl|   AllPub|   Inside|      Gtl|     Gilbert|      Norm|      Norm|    1Fam|    1Story|          7|          5|     1990|        1990|    Gable| CompShg|    HdBoard|    HdBoard|      None|         0|       TA|       TA|     PConc|      Gd|      TA|          Gd|         GLQ|       637|         Unf|         0|      663|       1300|   GasA|       Gd|         Y|     SBrkr|    1341|       0|           0|     1341|           1|           0|       1|       1|           2|           1|         Gd|           5|       Typ|         1|         Po|    Attchd|       1990|         Unf|         2|       506|        TA|        TA|         Y|       192|          0|            0|        0|          0|       0|    NA|   NA|         NA|      0|     2|  2010|      WD|       Normal|\n",
      "|1470|        20|      RL|         70|   8400|  Pave|   NA|     Reg|        Lvl|   AllPub|   Corner|      Gtl|       NAmes|      Norm|      Norm|    1Fam|    1Story|          4|          5|     1970|        1970|    Gable| CompShg|    Plywood|    Plywood|      None|         0|       TA|       TA|    CBlock|      TA|      TA|          No|         ALQ|       804|         Rec|        78|        0|        882|   GasA|       TA|         Y|     SBrkr|     882|       0|           0|      882|           1|           0|       1|       0|           2|           1|         TA|           4|       Typ|         0|         NA|    Attchd|       1970|         Fin|         2|       525|        TA|        TA|         Y|       240|          0|            0|        0|          0|       0|    NA|MnPrv|         NA|      0|     4|  2010|      WD|       Normal|\n",
      "|1471|       120|      RH|         26|   5858|  Pave|   NA|     IR1|        Lvl|   AllPub|      FR2|      Gtl|       NAmes|      Norm|      Norm|  TwnhsE|    1Story|          7|          5|     1999|        1999|    Gable| CompShg|    MetalSd|    MetalSd|      None|         0|       Gd|       TA|     PConc|      Gd|      TA|          No|         GLQ|      1051|         BLQ|         0|      354|       1405|   GasA|       Ex|         Y|     SBrkr|    1337|       0|           0|     1337|           1|           0|       2|       0|           2|           1|         Gd|           5|       Typ|         1|         Fa|    Attchd|       1999|         Fin|         2|       511|        TA|        TA|         Y|       203|         68|            0|        0|          0|       0|    NA|   NA|         NA|      0|     6|  2010|      WD|       Normal|\n",
      "|1472|       160|      RM|         21|   1680|  Pave|   NA|     Reg|        Lvl|   AllPub|   Inside|      Gtl|      BrDale|      Norm|      Norm|   Twnhs|    2Story|          6|          5|     1971|        1971|    Gable| CompShg|    HdBoard|    HdBoard|   BrkFace|       504|       TA|       TA|    CBlock|      TA|      TA|          No|         Rec|       156|         Unf|         0|      327|        483|   GasA|       TA|         Y|     SBrkr|     483|     504|           0|      987|           0|           0|       1|       1|           2|           1|         TA|           5|       Typ|         0|         NA|    Detchd|       1971|         Unf|         1|       264|        TA|        TA|         Y|       275|          0|            0|        0|          0|       0|    NA|   NA|         NA|      0|     2|  2010|     COD|       Normal|\n",
      "|1473|       160|      RM|         21|   1680|  Pave|   NA|     Reg|        Lvl|   AllPub|   Inside|      Gtl|      BrDale|      Norm|      Norm|   Twnhs|    2Story|          5|          5|     1971|        1971|    Gable| CompShg|    HdBoard|    HdBoard|   BrkFace|       492|       TA|       TA|    CBlock|      TA|      TA|          No|         Rec|       300|         Unf|         0|      225|        525|   GasA|       TA|         Y|     SBrkr|     525|     567|           0|     1092|           0|           0|       1|       1|           3|           1|         TA|           6|       Typ|         0|         NA|    Detchd|       1997|         Unf|         1|       320|        TA|        TA|         Y|         0|          0|            0|        0|          0|       0|    NA|   NA|         NA|      0|     3|  2010|      WD|       Normal|\n",
      "|1474|       160|      RL|         24|   2280|  Pave|   NA|     Reg|        Lvl|   AllPub|      FR2|      Gtl|     NPkVill|      Norm|      Norm|   Twnhs|    2Story|          6|          6|     1975|        1975|    Gable| CompShg|    Plywood|    Brk Cmn|      None|         0|       TA|       TA|    CBlock|      TA|      TA|          No|         ALQ|       514|         Unf|         0|      341|        855|   GasA|       TA|         Y|     SBrkr|     855|     601|           0|     1456|           0|           0|       2|       1|           3|           1|         Gd|           6|       Typ|         1|         TA|    Attchd|       1975|         Unf|         2|       440|        TA|        TA|         Y|       173|          0|            0|        0|          0|       0|    NA|   NA|         NA|      0|     6|  2010|      WD|       Normal|\n",
      "|1475|       120|      RL|         24|   2280|  Pave|   NA|     Reg|        Lvl|   AllPub|      FR2|      Gtl|     NPkVill|      Norm|      Norm|   Twnhs|    1Story|          7|          6|     1975|        1975|    Gable| CompShg|    Plywood|    Brk Cmn|      None|         0|       TA|       TA|    CBlock|      Gd|      TA|          No|         Unf|         0|         Unf|         0|      836|        836|   GasA|       Ex|         Y|     SBrkr|     836|       0|           0|      836|           0|           0|       1|       0|           2|           1|         TA|           4|       Typ|         0|         NA|    Attchd|       1975|         Unf|         1|       308|        TA|        TA|         Y|         0|         30|            0|        0|          0|       0|    NA|   NA|         NA|      0|     6|  2010|      WD|       Normal|\n",
      "|1476|        60|      RL|        102|  12858|  Pave|   NA|     IR1|        Lvl|   AllPub|   Inside|      Gtl|     NridgHt|      Norm|      Norm|    1Fam|    2Story|          9|          5|     2009|        2010|    Gable| CompShg|    VinylSd|    VinylSd|     Stone|       162|       Ex|       TA|     PConc|      Ex|      TA|          No|         Unf|         0|         Unf|         0|     1590|       1590|   GasA|       Ex|         Y|     SBrkr|    1627|     707|           0|     2334|           0|           0|       2|       1|           3|           1|         Ex|          10|       Typ|         1|         Gd|    Attchd|       2009|         Fin|         3|       751|        TA|        TA|         Y|       144|        133|            0|        0|          0|       0|    NA|   NA|         NA|      0|     1|  2010|     New|      Partial|\n",
      "|1477|        20|      RL|         94|  12883|  Pave|   NA|     IR1|        Lvl|   AllPub|   Corner|      Gtl|     NridgHt|      Norm|      Norm|    1Fam|    1Story|          8|          5|     2009|        2010|    Gable| CompShg|    VinylSd|    VinylSd|     Stone|       256|       Gd|       TA|     PConc|      Gd|      TA|          No|         Unf|         0|         Unf|         0|     1544|       1544|   GasA|       Ex|         Y|     SBrkr|    1544|       0|           0|     1544|           0|           0|       2|       0|           3|           1|         Gd|           7|       Typ|         0|         NA|    Attchd|       2009|         RFn|         3|       868|        TA|        TA|         Y|         0|         35|            0|        0|          0|       0|    NA|   NA|         NA|      0|     6|  2010|     New|      Partial|\n",
      "|1478|        20|      RL|         90|  11520|  Pave|   NA|     Reg|        Lvl|   AllPub|   Inside|      Gtl|     NridgHt|      PosN|      Norm|    1Fam|    1Story|          9|          5|     2005|        2005|      Hip| CompShg|    VinylSd|    VinylSd|   BrkFace|       615|       Gd|       TA|     PConc|      Ex|      TA|          No|         GLQ|       110|         Unf|         0|     1588|       1698|   GasA|       Ex|         Y|     SBrkr|    1698|       0|           0|     1698|           0|           0|       2|       0|           3|           1|         Ex|           7|       Typ|         1|         Gd|    Attchd|       2005|         Fin|         3|       730|        TA|        TA|         Y|       192|         74|            0|        0|          0|       0|    NA|   NA|         NA|      0|     6|  2010|      WD|       Normal|\n",
      "|1479|        20|      RL|         79|  14122|  Pave|   NA|     IR1|        Lvl|   AllPub|   Inside|      Gtl|     NridgHt|      Norm|      Norm|    1Fam|    1Story|          8|          5|     2005|        2006|      Hip| CompShg|    CemntBd|    CmentBd|   BrkFace|       240|       Gd|       TA|     PConc|      Ex|      TA|          No|         GLQ|        28|         Unf|         0|     1794|       1822|   GasA|       Ex|         Y|     SBrkr|    1822|       0|           0|     1822|           0|           0|       2|       0|           3|           1|         Ex|           8|       Typ|         1|         Gd|    Attchd|       2005|         RFn|         3|       678|        TA|        TA|         Y|         0|        119|            0|        0|          0|       0|    NA|   NA|         NA|      0|     2|  2010|      WD|       Normal|\n",
      "|1480|        20|      RL|        110|  14300|  Pave|   NA|     Reg|        HLS|   AllPub|   Inside|      Mod|     NridgHt|      Norm|      Norm|    1Fam|    1Story|          9|          5|     2003|        2004|      Hip| CompShg|    VinylSd|    VinylSd|   BrkFace|      1095|       Ex|       TA|     PConc|      Ex|      TA|          Gd|         GLQ|      1373|         Unf|         0|     1473|       2846|   GasA|       Ex|         Y|     SBrkr|    2696|       0|           0|     2696|           1|           0|       2|       1|           3|           1|         Ex|          10|       Typ|         2|         Gd|    Attchd|       2003|         Fin|         3|       958|        TA|        TA|         Y|       220|        150|            0|        0|          0|       0|    NA|   NA|         NA|      0|     6|  2010|      WD|       Normal|\n",
      "+----+----------+--------+-----------+-------+------+-----+--------+-----------+---------+---------+---------+------------+----------+----------+--------+----------+-----------+-----------+---------+------------+---------+--------+-----------+-----------+----------+----------+---------+---------+----------+--------+--------+------------+------------+----------+------------+----------+---------+-----------+-------+---------+----------+----------+--------+--------+------------+---------+------------+------------+--------+--------+------------+------------+-----------+------------+----------+----------+-----------+----------+-----------+------------+----------+----------+----------+----------+----------+----------+-----------+-------------+---------+-----------+--------+------+-----+-----------+-------+------+------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.show(), test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e2625f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sale price : Label\n",
    "# features: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eec038d",
   "metadata": {},
   "source": [
    "# 전처리 : 결측치 = 0  \n",
    "\n",
    "- 숫자 타입 통일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88239c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 0 \n",
    "train_df = train_df.fillna(0)\n",
    "test_df = test_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ef041ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 타입 변환\n",
    "# train_df 의 GarageCars 와 GarageArea 컬럼은 integer 인데 test_df 는 string 임 -> integer로 변환\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# GarageCars, GarageArea 컬럼을 정수형으로 변환\n",
    "train_df = train_df.withColumn(\"GarageArea\", train_df[\"GarageArea\"].cast(\"integer\"))\n",
    "train_df = train_df.withColumn(\"GarageCars\", train_df[\"GarageCars\"].cast(\"integer\"))\n",
    "test_df = test_df.withColumn(\"GarageArea\", test_df[\"GarageArea\"].cast(\"integer\"))\n",
    "test_df = test_df.withColumn(\"GarageCars\", test_df[\"GarageCars\"].cast(\"integer\"))\n",
    "                                                              \n",
    "# test_df = test_df.withColumn(\"GarageCars\", col(\"GarageCars\").cast(\"integer\"))\n",
    "# test_df = test_df.withColumn(\"GarageArea\", col(\"GarageArea\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a619b668",
   "metadata": {},
   "source": [
    "# Encoding \n",
    "- 문자형 > 숫자형 1,2,3,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d057b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
    "\n",
    "#1,2,3,4 로 값을 단순화\n",
    "string_columns = [\"Neighborhood\"]\n",
    "indexers = [StringIndexer(inputCol=col, outputCol= col+\"_index\") for col in string_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5096daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehotencoding : 범주형 변수 1,2,3,4 -> 1로 바꾸는 인코딩\n",
    "encoders = [OneHotEncoder(inputCol=col+\"_index\", outputCol= col+\"_encoded\") for col in string_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a762addb",
   "metadata": {},
   "source": [
    "# Features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "600efbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\"LotArea\", \"OverallQual\", \"OverallCond\", \"YearBuilt\", \"YearRemodAdd\", \n",
    "    \"1stFlrSF\", \"2ndFlrSF\", \"GrLivArea\", \"GarageCars\", \"GarageArea\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67714f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자형(인코딩) + 숫자형 피처를 겨람한 모델 입력 생성\n",
    "assembler_inputs = [col+\"_encoded\" for col in string_columns] + numeric_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579e3549",
   "metadata": {},
   "source": [
    "# Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f736ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols= assembler_inputs, outputCol=\"features\", handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd4d5f",
   "metadata": {},
   "source": [
    "# Label selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "721415f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.withColumnRenamed(\"SalePrice\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bbadf04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+-----------+-------+------+-----+--------+-----------+---------+---------+---------+------------+----------+----------+--------+----------+-----------+-----------+---------+------------+---------+--------+-----------+-----------+----------+----------+---------+---------+----------+--------+--------+------------+------------+----------+------------+----------+---------+-----------+-------+---------+----------+----------+--------+--------+------------+---------+------------+------------+--------+--------+------------+------------+-----------+------------+----------+----------+-----------+----------+-----------+------------+----------+----------+----------+----------+----------+----------+-----------+-------------+---------+-----------+--------+------+-----+-----------+-------+------+------+--------+-------------+------+\n",
      "| Id|MSSubClass|MSZoning|LotFrontage|LotArea|Street|Alley|LotShape|LandContour|Utilities|LotConfig|LandSlope|Neighborhood|Condition1|Condition2|BldgType|HouseStyle|OverallQual|OverallCond|YearBuilt|YearRemodAdd|RoofStyle|RoofMatl|Exterior1st|Exterior2nd|MasVnrType|MasVnrArea|ExterQual|ExterCond|Foundation|BsmtQual|BsmtCond|BsmtExposure|BsmtFinType1|BsmtFinSF1|BsmtFinType2|BsmtFinSF2|BsmtUnfSF|TotalBsmtSF|Heating|HeatingQC|CentralAir|Electrical|1stFlrSF|2ndFlrSF|LowQualFinSF|GrLivArea|BsmtFullBath|BsmtHalfBath|FullBath|HalfBath|BedroomAbvGr|KitchenAbvGr|KitchenQual|TotRmsAbvGrd|Functional|Fireplaces|FireplaceQu|GarageType|GarageYrBlt|GarageFinish|GarageCars|GarageArea|GarageQual|GarageCond|PavedDrive|WoodDeckSF|OpenPorchSF|EnclosedPorch|3SsnPorch|ScreenPorch|PoolArea|PoolQC|Fence|MiscFeature|MiscVal|MoSold|YrSold|SaleType|SaleCondition| label|\n",
      "+---+----------+--------+-----------+-------+------+-----+--------+-----------+---------+---------+---------+------------+----------+----------+--------+----------+-----------+-----------+---------+------------+---------+--------+-----------+-----------+----------+----------+---------+---------+----------+--------+--------+------------+------------+----------+------------+----------+---------+-----------+-------+---------+----------+----------+--------+--------+------------+---------+------------+------------+--------+--------+------------+------------+-----------+------------+----------+----------+-----------+----------+-----------+------------+----------+----------+----------+----------+----------+----------+-----------+-------------+---------+-----------+--------+------+-----+-----------+-------+------+------+--------+-------------+------+\n",
      "|  1|        60|      RL|         65|   8450|  Pave|   NA|     Reg|        Lvl|   AllPub|   Inside|      Gtl|     CollgCr|      Norm|      Norm|    1Fam|    2Story|          7|          5|     2003|        2003|    Gable| CompShg|    VinylSd|    VinylSd|   BrkFace|       196|       Gd|       TA|     PConc|      Gd|      TA|          No|         GLQ|       706|         Unf|         0|      150|        856|   GasA|       Ex|         Y|     SBrkr|     856|     854|           0|     1710|           1|           0|       2|       1|           3|           1|         Gd|           8|       Typ|         0|         NA|    Attchd|       2003|         RFn|         2|       548|        TA|        TA|         Y|         0|         61|            0|        0|          0|       0|    NA|   NA|         NA|      0|     2|  2008|      WD|       Normal|208500|\n",
      "|  2|        20|      RL|         80|   9600|  Pave|   NA|     Reg|        Lvl|   AllPub|      FR2|      Gtl|     Veenker|     Feedr|      Norm|    1Fam|    1Story|          6|          8|     1976|        1976|    Gable| CompShg|    MetalSd|    MetalSd|      None|         0|       TA|       TA|    CBlock|      Gd|      TA|          Gd|         ALQ|       978|         Unf|         0|      284|       1262|   GasA|       Ex|         Y|     SBrkr|    1262|       0|           0|     1262|           0|           1|       2|       0|           3|           1|         TA|           6|       Typ|         1|         TA|    Attchd|       1976|         RFn|         2|       460|        TA|        TA|         Y|       298|          0|            0|        0|          0|       0|    NA|   NA|         NA|      0|     5|  2007|      WD|       Normal|181500|\n",
      "|  3|        60|      RL|         68|  11250|  Pave|   NA|     IR1|        Lvl|   AllPub|   Inside|      Gtl|     CollgCr|      Norm|      Norm|    1Fam|    2Story|          7|          5|     2001|        2002|    Gable| CompShg|    VinylSd|    VinylSd|   BrkFace|       162|       Gd|       TA|     PConc|      Gd|      TA|          Mn|         GLQ|       486|         Unf|         0|      434|        920|   GasA|       Ex|         Y|     SBrkr|     920|     866|           0|     1786|           1|           0|       2|       1|           3|           1|         Gd|           6|       Typ|         1|         TA|    Attchd|       2001|         RFn|         2|       608|        TA|        TA|         Y|         0|         42|            0|        0|          0|       0|    NA|   NA|         NA|      0|     9|  2008|      WD|       Normal|223500|\n",
      "+---+----------+--------+-----------+-------+------+-----+--------+-----------+---------+---------+---------+------------+----------+----------+--------+----------+-----------+-----------+---------+------------+---------+--------+-----------+-----------+----------+----------+---------+---------+----------+--------+--------+------------+------------+----------+------------+----------+---------+-----------+-------+---------+----------+----------+--------+--------+------------+---------+------------+------------+--------+--------+------------+------------+-----------+------------+----------+----------+-----------+----------+-----------+------------+----------+----------+----------+----------+----------+----------+-----------+-------------+---------+-----------+--------+------+-----+-----------+-------+------+------+--------+-------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1152ba8",
   "metadata": {},
   "source": [
    "# Pipeline 설정\n",
    "- StringIndex + OneHotEncoder + Assembler >> 하나의 SparkML Pipeline 으로 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f279ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d04a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline 생성\n",
    "pipeline = Pipeline(stages = indexers+encoders+[assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "645f4006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline 실행\n",
    "pipeline_model = pipeline.fit( train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc1b8ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline 실행 후 변환\n",
    "train_transformed = pipeline_model.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef53e174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b32ecf0",
   "metadata": {},
   "source": [
    "# 모델 생성 : 회귀 - 모델 학습 > 평가 > 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9cda801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aabe3a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/13 10:27:48 WARN Instrumentation: [b82916f9] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(featuresCol=\"features\",labelCol=\"label\")\n",
    "\n",
    "# 모델 학습\n",
    "lr_model = lr.fit(train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40297d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 - 데이터를 이용한 평가 > FIT 은 안함 - FIT 은 모델 맞춤 과정, 테스트 데이터에 의해 규칙이 변화\n",
    "test_transformed = pipeline_model.transform(test_df)\n",
    "predictions = lr_model.transform(test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3576a943",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- MSSubClass: integer (nullable = true)\n",
      " |-- MSZoning: string (nullable = true)\n",
      " |-- LotFrontage: string (nullable = true)\n",
      " |-- LotArea: integer (nullable = true)\n",
      " |-- Street: string (nullable = true)\n",
      " |-- Alley: string (nullable = true)\n",
      " |-- LotShape: string (nullable = true)\n",
      " |-- LandContour: string (nullable = true)\n",
      " |-- Utilities: string (nullable = true)\n",
      " |-- LotConfig: string (nullable = true)\n",
      " |-- LandSlope: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Condition1: string (nullable = true)\n",
      " |-- Condition2: string (nullable = true)\n",
      " |-- BldgType: string (nullable = true)\n",
      " |-- HouseStyle: string (nullable = true)\n",
      " |-- OverallQual: integer (nullable = true)\n",
      " |-- OverallCond: integer (nullable = true)\n",
      " |-- YearBuilt: integer (nullable = true)\n",
      " |-- YearRemodAdd: integer (nullable = true)\n",
      " |-- RoofStyle: string (nullable = true)\n",
      " |-- RoofMatl: string (nullable = true)\n",
      " |-- Exterior1st: string (nullable = true)\n",
      " |-- Exterior2nd: string (nullable = true)\n",
      " |-- MasVnrType: string (nullable = true)\n",
      " |-- MasVnrArea: string (nullable = true)\n",
      " |-- ExterQual: string (nullable = true)\n",
      " |-- ExterCond: string (nullable = true)\n",
      " |-- Foundation: string (nullable = true)\n",
      " |-- BsmtQual: string (nullable = true)\n",
      " |-- BsmtCond: string (nullable = true)\n",
      " |-- BsmtExposure: string (nullable = true)\n",
      " |-- BsmtFinType1: string (nullable = true)\n",
      " |-- BsmtFinSF1: string (nullable = true)\n",
      " |-- BsmtFinType2: string (nullable = true)\n",
      " |-- BsmtFinSF2: string (nullable = true)\n",
      " |-- BsmtUnfSF: string (nullable = true)\n",
      " |-- TotalBsmtSF: string (nullable = true)\n",
      " |-- Heating: string (nullable = true)\n",
      " |-- HeatingQC: string (nullable = true)\n",
      " |-- CentralAir: string (nullable = true)\n",
      " |-- Electrical: string (nullable = true)\n",
      " |-- 1stFlrSF: integer (nullable = true)\n",
      " |-- 2ndFlrSF: integer (nullable = true)\n",
      " |-- LowQualFinSF: integer (nullable = true)\n",
      " |-- GrLivArea: integer (nullable = true)\n",
      " |-- BsmtFullBath: string (nullable = true)\n",
      " |-- BsmtHalfBath: string (nullable = true)\n",
      " |-- FullBath: integer (nullable = true)\n",
      " |-- HalfBath: integer (nullable = true)\n",
      " |-- BedroomAbvGr: integer (nullable = true)\n",
      " |-- KitchenAbvGr: integer (nullable = true)\n",
      " |-- KitchenQual: string (nullable = true)\n",
      " |-- TotRmsAbvGrd: integer (nullable = true)\n",
      " |-- Functional: string (nullable = true)\n",
      " |-- Fireplaces: integer (nullable = true)\n",
      " |-- FireplaceQu: string (nullable = true)\n",
      " |-- GarageType: string (nullable = true)\n",
      " |-- GarageYrBlt: string (nullable = true)\n",
      " |-- GarageFinish: string (nullable = true)\n",
      " |-- GarageCars: integer (nullable = true)\n",
      " |-- GarageArea: integer (nullable = true)\n",
      " |-- GarageQual: string (nullable = true)\n",
      " |-- GarageCond: string (nullable = true)\n",
      " |-- PavedDrive: string (nullable = true)\n",
      " |-- WoodDeckSF: integer (nullable = true)\n",
      " |-- OpenPorchSF: integer (nullable = true)\n",
      " |-- EnclosedPorch: integer (nullable = true)\n",
      " |-- 3SsnPorch: integer (nullable = true)\n",
      " |-- ScreenPorch: integer (nullable = true)\n",
      " |-- PoolArea: integer (nullable = true)\n",
      " |-- PoolQC: string (nullable = true)\n",
      " |-- Fence: string (nullable = true)\n",
      " |-- MiscFeature: string (nullable = true)\n",
      " |-- MiscVal: integer (nullable = true)\n",
      " |-- MoSold: integer (nullable = true)\n",
      " |-- YrSold: integer (nullable = true)\n",
      " |-- SaleType: string (nullable = true)\n",
      " |-- SaleCondition: string (nullable = true)\n",
      " |-- Neighborhood_index: double (nullable = false)\n",
      " |-- Neighborhood_encoded: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예측값 확인\n",
    "predictions.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "875ff7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------------+\n",
      "|  id|            features|        prediction|\n",
      "+----+--------------------+------------------+\n",
      "|1461|(34,[0,24,25,26,2...|114113.60325331613|\n",
      "|1462|(34,[0,24,25,26,2...| 156145.8445868329|\n",
      "|1463|(34,[5,24,25,26,2...| 168254.6697326172|\n",
      "|1464|(34,[5,24,25,26,2...|186898.44701529457|\n",
      "|1465|(34,[18,24,25,26,...| 263561.2240313499|\n",
      "|1466|(34,[5,24,25,26,2...|175809.50195952365|\n",
      "|1467|(34,[5,24,25,26,2...| 178614.1366187206|\n",
      "|1468|(34,[5,24,25,26,2...|169044.90403965162|\n",
      "|1469|(34,[5,24,25,26,2...|189982.47999848984|\n",
      "|1470|(34,[0,24,25,26,2...| 102005.8108274308|\n",
      "+----+--------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"id\",\"features\",\"prediction\").show(10, truncate=True) # truncate False는 피처값을 다 보여줌 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d833abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/13 10:41:13 ERROR Utils: Aborting task\n",
      "org.apache.spark.SparkException: Failed to execute user defined function(VectorAssembler$$Lambda$3060/1785103133: (struct<Neighborhood_encoded:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>,LotArea_double_VectorAssembler_a704e5526f9b:double,OverallQual_double_VectorAssembler_a704e5526f9b:double,OverallCond_double_VectorAssembler_a704e5526f9b:double,YearBuilt_double_VectorAssembler_a704e5526f9b:double,YearRemodAdd_double_VectorAssembler_a704e5526f9b:double,1stFlrSF_double_VectorAssembler_a704e5526f9b:double,2ndFlrSF_double_VectorAssembler_a704e5526f9b:double,GrLivArea_double_VectorAssembler_a704e5526f9b:double,GarageCars_double_VectorAssembler_a704e5526f9b:double,GarageArea_double_VectorAssembler_a704e5526f9b:double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"error\". Consider\n",
      "removing nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1(VectorAssembler.scala:291)\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1$adapted(VectorAssembler.scala:260)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:260)\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler.$anonfun$transform$6(VectorAssembler.scala:143)\n",
      "\t... 15 more\n",
      "24/12/13 10:41:13 ERROR FileFormatWriter: Job job_202412131041138019587389616338971_0028 aborted.\n",
      "24/12/13 10:41:13 ERROR Executor: Exception in task 0.0 in stage 28.0 (TID 28)\n",
      "org.apache.spark.SparkException: Task failed while writing rows.\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:296)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Failed to execute user defined function(VectorAssembler$$Lambda$3060/1785103133: (struct<Neighborhood_encoded:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>,LotArea_double_VectorAssembler_a704e5526f9b:double,OverallQual_double_VectorAssembler_a704e5526f9b:double,OverallCond_double_VectorAssembler_a704e5526f9b:double,YearBuilt_double_VectorAssembler_a704e5526f9b:double,YearRemodAdd_double_VectorAssembler_a704e5526f9b:double,1stFlrSF_double_VectorAssembler_a704e5526f9b:double,2ndFlrSF_double_VectorAssembler_a704e5526f9b:double,GrLivArea_double_VectorAssembler_a704e5526f9b:double,GarageCars_double_VectorAssembler_a704e5526f9b:double,GarageArea_double_VectorAssembler_a704e5526f9b:double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n",
      "\t... 9 more\n",
      "Caused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"error\". Consider\n",
      "removing nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1(VectorAssembler.scala:291)\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1$adapted(VectorAssembler.scala:260)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:260)\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler.$anonfun$transform$6(VectorAssembler.scala:143)\n",
      "\t... 15 more\n",
      "24/12/13 10:41:13 WARN TaskSetManager: Lost task 0.0 in stage 28.0 (TID 28) (ip-172-31-2-110.ap-northeast-3.compute.internal executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:296)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Failed to execute user defined function(VectorAssembler$$Lambda$3060/1785103133: (struct<Neighborhood_encoded:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>,LotArea_double_VectorAssembler_a704e5526f9b:double,OverallQual_double_VectorAssembler_a704e5526f9b:double,OverallCond_double_VectorAssembler_a704e5526f9b:double,YearBuilt_double_VectorAssembler_a704e5526f9b:double,YearRemodAdd_double_VectorAssembler_a704e5526f9b:double,1stFlrSF_double_VectorAssembler_a704e5526f9b:double,2ndFlrSF_double_VectorAssembler_a704e5526f9b:double,GrLivArea_double_VectorAssembler_a704e5526f9b:double,GarageCars_double_VectorAssembler_a704e5526f9b:double,GarageArea_double_VectorAssembler_a704e5526f9b:double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n",
      "\t... 9 more\n",
      "Caused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"error\". Consider\n",
      "removing nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1(VectorAssembler.scala:291)\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1$adapted(VectorAssembler.scala:260)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:260)\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler.$anonfun$transform$6(VectorAssembler.scala:143)\n",
      "\t... 15 more\n",
      "\n",
      "24/12/13 10:41:13 ERROR TaskSetManager: Task 0 in stage 28.0 failed 1 times; aborting job\n",
      "24/12/13 10:41:13 ERROR FileFormatWriter: Aborting job 09d7f74d-c9a7-41e2-ac66-8cef6e080efa.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 28.0 failed 1 times, most recent failure: Lost task 0.0 in stage 28.0 (TID 28) (ip-172-31-2-110.ap-northeast-3.compute.internal executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:296)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Failed to execute user defined function(VectorAssembler$$Lambda$3060/1785103133: (struct<Neighborhood_encoded:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>,LotArea_double_VectorAssembler_a704e5526f9b:double,OverallQual_double_VectorAssembler_a704e5526f9b:double,OverallCond_double_VectorAssembler_a704e5526f9b:double,YearBuilt_double_VectorAssembler_a704e5526f9b:double,YearRemodAdd_double_VectorAssembler_a704e5526f9b:double,1stFlrSF_double_VectorAssembler_a704e5526f9b:double,2ndFlrSF_double_VectorAssembler_a704e5526f9b:double,GrLivArea_double_VectorAssembler_a704e5526f9b:double,GarageCars_double_VectorAssembler_a704e5526f9b:double,GarageArea_double_VectorAssembler_a704e5526f9b:double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n",
      "\t... 9 more\n",
      "Caused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"error\". Consider\n",
      "removing nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1(VectorAssembler.scala:291)\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1$adapted(VectorAssembler.scala:260)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:260)\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler.$anonfun$transform$6(VectorAssembler.scala:143)\n",
      "\t... 15 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:188)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:979)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Task failed while writing rows.\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:296)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "Caused by: org.apache.spark.SparkException: Failed to execute user defined function(VectorAssembler$$Lambda$3060/1785103133: (struct<Neighborhood_encoded:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>,LotArea_double_VectorAssembler_a704e5526f9b:double,OverallQual_double_VectorAssembler_a704e5526f9b:double,OverallCond_double_VectorAssembler_a704e5526f9b:double,YearBuilt_double_VectorAssembler_a704e5526f9b:double,YearRemodAdd_double_VectorAssembler_a704e5526f9b:double,1stFlrSF_double_VectorAssembler_a704e5526f9b:double,2ndFlrSF_double_VectorAssembler_a704e5526f9b:double,GrLivArea_double_VectorAssembler_a704e5526f9b:double,GarageCars_double_VectorAssembler_a704e5526f9b:double,GarageArea_double_VectorAssembler_a704e5526f9b:double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n",
      "\t... 9 more\n",
      "Caused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"error\". Consider\n",
      "removing nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1(VectorAssembler.scala:291)\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1$adapted(VectorAssembler.scala:260)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:260)\n",
      "\tat org.apache.spark.ml.feature.VectorAssembler.$anonfun$transform$6(VectorAssembler.scala:143)\n",
      "\t... 15 more\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o956.csv.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:231)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:188)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:979)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 28.0 failed 1 times, most recent failure: Lost task 0.0 in stage 28.0 (TID 28) (ip-172-31-2-110.ap-northeast-3.compute.internal executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:296)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function(VectorAssembler$$Lambda$3060/1785103133: (struct<Neighborhood_encoded:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>,LotArea_double_VectorAssembler_a704e5526f9b:double,OverallQual_double_VectorAssembler_a704e5526f9b:double,OverallCond_double_VectorAssembler_a704e5526f9b:double,YearBuilt_double_VectorAssembler_a704e5526f9b:double,YearRemodAdd_double_VectorAssembler_a704e5526f9b:double,1stFlrSF_double_VectorAssembler_a704e5526f9b:double,2ndFlrSF_double_VectorAssembler_a704e5526f9b:double,GrLivArea_double_VectorAssembler_a704e5526f9b:double,GarageCars_double_VectorAssembler_a704e5526f9b:double,GarageArea_double_VectorAssembler_a704e5526f9b:double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n\t... 9 more\nCaused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"error\". Consider\nremoving nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1(VectorAssembler.scala:291)\n\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1$adapted(VectorAssembler.scala:260)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:260)\n\tat org.apache.spark.ml.feature.VectorAssembler.$anonfun$transform$6(VectorAssembler.scala:143)\n\t... 15 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\n\t... 33 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:296)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function(VectorAssembler$$Lambda$3060/1785103133: (struct<Neighborhood_encoded:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>,LotArea_double_VectorAssembler_a704e5526f9b:double,OverallQual_double_VectorAssembler_a704e5526f9b:double,OverallCond_double_VectorAssembler_a704e5526f9b:double,YearBuilt_double_VectorAssembler_a704e5526f9b:double,YearRemodAdd_double_VectorAssembler_a704e5526f9b:double,1stFlrSF_double_VectorAssembler_a704e5526f9b:double,2ndFlrSF_double_VectorAssembler_a704e5526f9b:double,GrLivArea_double_VectorAssembler_a704e5526f9b:double,GarageCars_double_VectorAssembler_a704e5526f9b:double,GarageArea_double_VectorAssembler_a704e5526f9b:double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n\t... 9 more\nCaused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"error\". Consider\nremoving nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1(VectorAssembler.scala:291)\n\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1$adapted(VectorAssembler.scala:260)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:260)\n\tat org.apache.spark.ml.feature.VectorAssembler.$anonfun$transform$6(VectorAssembler.scala:143)\n\t... 15 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumnRenamed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSalePrice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/output/house_prediction.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/readwriter.py:1372\u001b[0m, in \u001b[0;36mDataFrameWriter.csv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode(mode)\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression, sep\u001b[38;5;241m=\u001b[39msep, quote\u001b[38;5;241m=\u001b[39mquote, escape\u001b[38;5;241m=\u001b[39mescape, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   1366\u001b[0m                nullValue\u001b[38;5;241m=\u001b[39mnullValue, escapeQuotes\u001b[38;5;241m=\u001b[39mescapeQuotes, quoteAll\u001b[38;5;241m=\u001b[39mquoteAll,\n\u001b[1;32m   1367\u001b[0m                dateFormat\u001b[38;5;241m=\u001b[39mdateFormat, timestampFormat\u001b[38;5;241m=\u001b[39mtimestampFormat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1370\u001b[0m                charToEscapeQuoteEscaping\u001b[38;5;241m=\u001b[39mcharToEscapeQuoteEscaping,\n\u001b[1;32m   1371\u001b[0m                encoding\u001b[38;5;241m=\u001b[39mencoding, emptyValue\u001b[38;5;241m=\u001b[39memptyValue, lineSep\u001b[38;5;241m=\u001b[39mlineSep)\n\u001b[0;32m-> 1372\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o956.csv.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:231)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:188)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:979)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 28.0 failed 1 times, most recent failure: Lost task 0.0 in stage 28.0 (TID 28) (ip-172-31-2-110.ap-northeast-3.compute.internal executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:296)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function(VectorAssembler$$Lambda$3060/1785103133: (struct<Neighborhood_encoded:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>,LotArea_double_VectorAssembler_a704e5526f9b:double,OverallQual_double_VectorAssembler_a704e5526f9b:double,OverallCond_double_VectorAssembler_a704e5526f9b:double,YearBuilt_double_VectorAssembler_a704e5526f9b:double,YearRemodAdd_double_VectorAssembler_a704e5526f9b:double,1stFlrSF_double_VectorAssembler_a704e5526f9b:double,2ndFlrSF_double_VectorAssembler_a704e5526f9b:double,GrLivArea_double_VectorAssembler_a704e5526f9b:double,GarageCars_double_VectorAssembler_a704e5526f9b:double,GarageArea_double_VectorAssembler_a704e5526f9b:double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n\t... 9 more\nCaused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"error\". Consider\nremoving nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1(VectorAssembler.scala:291)\n\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1$adapted(VectorAssembler.scala:260)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:260)\n\tat org.apache.spark.ml.feature.VectorAssembler.$anonfun$transform$6(VectorAssembler.scala:143)\n\t... 15 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:200)\n\t... 33 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:296)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function(VectorAssembler$$Lambda$3060/1785103133: (struct<Neighborhood_encoded:struct<type:tinyint,size:int,indices:array<int>,values:array<double>>,LotArea_double_VectorAssembler_a704e5526f9b:double,OverallQual_double_VectorAssembler_a704e5526f9b:double,OverallCond_double_VectorAssembler_a704e5526f9b:double,YearBuilt_double_VectorAssembler_a704e5526f9b:double,YearRemodAdd_double_VectorAssembler_a704e5526f9b:double,1stFlrSF_double_VectorAssembler_a704e5526f9b:double,2ndFlrSF_double_VectorAssembler_a704e5526f9b:double,GrLivArea_double_VectorAssembler_a704e5526f9b:double,GarageCars_double_VectorAssembler_a704e5526f9b:double,GarageArea_double_VectorAssembler_a704e5526f9b:double>) => struct<type:tinyint,size:int,indices:array<int>,values:array<double>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:277)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1473)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n\t... 9 more\nCaused by: org.apache.spark.SparkException: Encountered null while assembling a row with handleInvalid = \"error\". Consider\nremoving nulls from dataset or using handleInvalid = \"keep\" or \"skip\".\n\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1(VectorAssembler.scala:291)\n\tat org.apache.spark.ml.feature.VectorAssembler$.$anonfun$assemble$1$adapted(VectorAssembler.scala:260)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38)\n\tat org.apache.spark.ml.feature.VectorAssembler$.assemble(VectorAssembler.scala:260)\n\tat org.apache.spark.ml.feature.VectorAssembler.$anonfun$transform$6(VectorAssembler.scala:143)\n\t... 15 more\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"id\", \"prediction\") \\\n",
    ".withColumnRenamed('prediction', 'SalePrice') \\\n",
    ".write.csv('data/output/house_prediction.csv', header=True, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d0226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값 읽어서 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee642e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07fd5a7e",
   "metadata": {},
   "source": [
    "# 예측 모델의 활용\n",
    "\n",
    "1. 파이프라인 저장 > 로컬 data/output > 모델저장소에 저장\n",
    "2. 모델 저장 > 로컬 > 모델 저장소에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f8d0ee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved..\n"
     ]
    }
   ],
   "source": [
    "model_save_path = 'data/output/boston_housing_lr_model'\n",
    "pipeline_save_path = 'data/output/boston_housing_pipeline_model'\n",
    "\n",
    "# 파이파라인 모델 > 새로운 데이터를 변환하기 위해 저장\n",
    "pipeline_model.write().overwrite().save(pipeline_save_path)\n",
    "\n",
    "#선형회귀모델 > 새로운 데이터로 예측하기 위해 저장\n",
    "lr_model.write().overwrite().save(model_save_path)\n",
    "print('model saved..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fc1f05",
   "metadata": {},
   "source": [
    "# 모델, 파이프라인 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "464c4f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.regression import LinearRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ba995213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_516886cf8fa1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_pipeline = PipelineModel.load(pipeline_save_path)\n",
    "loaded_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e364034b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModel: uid=LinearRegression_e29aa12be2d0, numFeatures=34"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = LinearRegressionModel.load(model_save_path)\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975b762d",
   "metadata": {},
   "source": [
    "# 새로운 데이터로 예측 \n",
    "\n",
    "1. 새로운 데이터 >>> ???\n",
    "2. 파이프라인모델을 이용해서 변환\n",
    "3. 모델에 넣어 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c91e4d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터 샘플 생성\n",
    "data = {\n",
    "    \"Id\": [1461],\n",
    "    \"MSSubClass\": [20],\n",
    "    \"MSZoning\": [\"RH\"],\n",
    "    \"LotFrontage\": [80],\n",
    "    \"LotArea\": [11622],\n",
    "    \"Street\": [\"Pave\"],\n",
    "    \"Alley\": [None],  # NA를 None으로 표현\n",
    "    \"LotShape\": [\"Reg\"],\n",
    "    \"LandContour\": [\"Lvl\"],\n",
    "    \"Utilities\": [\"AllPub\"],\n",
    "    \"LotConfig\": [\"Inside\"],\n",
    "    \"LandSlope\": [\"Gtl\"],\n",
    "    \"Neighborhood\": [\"NAmes\"],\n",
    "    \"Condition1\": [\"Feedr\"],\n",
    "    \"Condition2\": [\"Norm\"],\n",
    "    \"BldgType\": [\"1Fam\"],\n",
    "    \"HouseStyle\": [\"1Story\"],\n",
    "    \"OverallQual\": [5],\n",
    "    \"OverallCond\": [6],\n",
    "    \"YearBuilt\": [1961],\n",
    "    \"YearRemodAdd\": [1961],\n",
    "    \"RoofStyle\": [\"Gable\"],\n",
    "    \"RoofMatl\": [\"CompShg\"],\n",
    "    \"Exterior1st\": [\"VinylSd\"],\n",
    "    \"Exterior2nd\": [\"VinylSd\"],\n",
    "    \"MasVnrType\": [None],  # None은 NA를 의미\n",
    "    \"MasVnrArea\": [0],\n",
    "    \"ExterQual\": [\"TA\"],\n",
    "    \"ExterCond\": [\"TA\"],\n",
    "    \"Foundation\": [\"CBlock\"],\n",
    "    \"BsmtQual\": [\"TA\"],\n",
    "    \"BsmtCond\": [\"TA\"],\n",
    "    \"BsmtExposure\": [\"No\"],\n",
    "    \"BsmtFinType1\": [\"Rec\"],\n",
    "    \"BsmtFinSF1\": [468],\n",
    "    \"BsmtFinType2\": [\"LwQ\"],\n",
    "    \"BsmtFinSF2\": [144],\n",
    "    \"BsmtUnfSF\": [270],\n",
    "    \"TotalBsmtSF\": [882],\n",
    "    \"Heating\": [\"GasA\"],\n",
    "    \"HeatingQC\": [\"TA\"],\n",
    "    \"CentralAir\": [\"Y\"],\n",
    "    \"Electrical\": [\"SBrkr\"],\n",
    "    \"1stFlrSF\": [896],\n",
    "    \"2ndFlrSF\": [0],\n",
    "    \"LowQualFinSF\": [0],\n",
    "    \"GrLivArea\": [896],\n",
    "    \"BsmtFullBath\": [0],\n",
    "    \"BsmtHalfBath\": [0],\n",
    "    \"FullBath\": [1],\n",
    "    \"HalfBath\": [0],\n",
    "    \"BedroomAbvGr\": [2],\n",
    "    \"KitchenAbvGr\": [1],\n",
    "    \"KitchenQual\": [\"TA\"],\n",
    "    \"TotRmsAbvGrd\": [5],\n",
    "    \"Functional\": [\"Typ\"],\n",
    "    \"Fireplaces\": [0],\n",
    "    \"FireplaceQu\": [None],  # NA를 None으로 표현\n",
    "    \"GarageType\": [\"Attchd\"],\n",
    "    \"GarageYrBlt\": [1961],\n",
    "    \"GarageFinish\": [\"Unf\"],\n",
    "    \"GarageCars\": [1],\n",
    "    \"GarageArea\": [730],\n",
    "    \"GarageQual\": [\"TA\"],\n",
    "    \"GarageCond\": [\"TA\"],\n",
    "    \"PavedDrive\": [\"Y\"],\n",
    "    \"WoodDeckSF\": [140],\n",
    "    \"OpenPorchSF\": [0],\n",
    "    \"EnclosedPorch\": [0],\n",
    "    \"3SsnPorch\": [0],\n",
    "    \"ScreenPorch\": [120],\n",
    "    \"PoolArea\": [0],\n",
    "    \"PoolQC\": [None],  # NA를 None으로 표현\n",
    "    \"Fence\": [\"MnPrv\"],\n",
    "    \"MiscFeature\": [None],  # NA를 None으로 표현\n",
    "    \"MiscVal\": [0],\n",
    "    \"MoSold\": [6],\n",
    "    \"YrSold\": [2010],\n",
    "    \"SaleType\": [\"WD\"],\n",
    "    \"SaleCondition\":[\"Normal\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e457d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(data).to_csv(\"data/new_test_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0e15590e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- MSSubClass: integer (nullable = true)\n",
      " |-- MSZoning: string (nullable = true)\n",
      " |-- LotFrontage: integer (nullable = true)\n",
      " |-- LotArea: integer (nullable = true)\n",
      " |-- Street: string (nullable = true)\n",
      " |-- Alley: string (nullable = true)\n",
      " |-- LotShape: string (nullable = true)\n",
      " |-- LandContour: string (nullable = true)\n",
      " |-- Utilities: string (nullable = true)\n",
      " |-- LotConfig: string (nullable = true)\n",
      " |-- LandSlope: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Condition1: string (nullable = true)\n",
      " |-- Condition2: string (nullable = true)\n",
      " |-- BldgType: string (nullable = true)\n",
      " |-- HouseStyle: string (nullable = true)\n",
      " |-- OverallQual: integer (nullable = true)\n",
      " |-- OverallCond: integer (nullable = true)\n",
      " |-- YearBuilt: integer (nullable = true)\n",
      " |-- YearRemodAdd: integer (nullable = true)\n",
      " |-- RoofStyle: string (nullable = true)\n",
      " |-- RoofMatl: string (nullable = true)\n",
      " |-- Exterior1st: string (nullable = true)\n",
      " |-- Exterior2nd: string (nullable = true)\n",
      " |-- MasVnrType: string (nullable = true)\n",
      " |-- MasVnrArea: integer (nullable = true)\n",
      " |-- ExterQual: string (nullable = true)\n",
      " |-- ExterCond: string (nullable = true)\n",
      " |-- Foundation: string (nullable = true)\n",
      " |-- BsmtQual: string (nullable = true)\n",
      " |-- BsmtCond: string (nullable = true)\n",
      " |-- BsmtExposure: string (nullable = true)\n",
      " |-- BsmtFinType1: string (nullable = true)\n",
      " |-- BsmtFinSF1: integer (nullable = true)\n",
      " |-- BsmtFinType2: string (nullable = true)\n",
      " |-- BsmtFinSF2: integer (nullable = true)\n",
      " |-- BsmtUnfSF: integer (nullable = true)\n",
      " |-- TotalBsmtSF: integer (nullable = true)\n",
      " |-- Heating: string (nullable = true)\n",
      " |-- HeatingQC: string (nullable = true)\n",
      " |-- CentralAir: string (nullable = true)\n",
      " |-- Electrical: string (nullable = true)\n",
      " |-- 1stFlrSF: integer (nullable = true)\n",
      " |-- 2ndFlrSF: integer (nullable = true)\n",
      " |-- LowQualFinSF: integer (nullable = true)\n",
      " |-- GrLivArea: integer (nullable = true)\n",
      " |-- BsmtFullBath: integer (nullable = true)\n",
      " |-- BsmtHalfBath: integer (nullable = true)\n",
      " |-- FullBath: integer (nullable = true)\n",
      " |-- HalfBath: integer (nullable = true)\n",
      " |-- BedroomAbvGr: integer (nullable = true)\n",
      " |-- KitchenAbvGr: integer (nullable = true)\n",
      " |-- KitchenQual: string (nullable = true)\n",
      " |-- TotRmsAbvGrd: integer (nullable = true)\n",
      " |-- Functional: string (nullable = true)\n",
      " |-- Fireplaces: integer (nullable = true)\n",
      " |-- FireplaceQu: string (nullable = true)\n",
      " |-- GarageType: string (nullable = true)\n",
      " |-- GarageYrBlt: integer (nullable = true)\n",
      " |-- GarageFinish: string (nullable = true)\n",
      " |-- GarageCars: integer (nullable = true)\n",
      " |-- GarageArea: integer (nullable = true)\n",
      " |-- GarageQual: string (nullable = true)\n",
      " |-- GarageCond: string (nullable = true)\n",
      " |-- PavedDrive: string (nullable = true)\n",
      " |-- WoodDeckSF: integer (nullable = true)\n",
      " |-- OpenPorchSF: integer (nullable = true)\n",
      " |-- EnclosedPorch: integer (nullable = true)\n",
      " |-- 3SsnPorch: integer (nullable = true)\n",
      " |-- ScreenPorch: integer (nullable = true)\n",
      " |-- PoolArea: integer (nullable = true)\n",
      " |-- PoolQC: string (nullable = true)\n",
      " |-- Fence: string (nullable = true)\n",
      " |-- MiscFeature: string (nullable = true)\n",
      " |-- MiscVal: integer (nullable = true)\n",
      " |-- MoSold: integer (nullable = true)\n",
      " |-- YrSold: integer (nullable = true)\n",
      " |-- SaleType: string (nullable = true)\n",
      " |-- SaleCondition: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_test_data = spark.read.csv(\"data/new_test_data.csv\", header=True, inferSchema=True)\n",
    "new_test_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d801ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#파이프라인 변환해서 모델에 넣어주기\n",
    "\n",
    "#파이프라인에 새로운 데이터를 넣어 준다\n",
    "new_pipe = loaded_pipeline.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb2a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdaf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 변환한 데이터를 모델에 넣어준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd95c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = loaded_model.transform(new_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "39c49a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f37ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred.select().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad11588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298f58aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00fc9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark_start",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
