{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123f01a2",
   "metadata": {},
   "source": [
    "# 타이타닉 데이터 분석 \n",
    "\n",
    "- 데이터 출처 : https://www.kaggle.com/competitions/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5de0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/12 10:58:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-2-110.ap-northeast-3.compute.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>241212_01_MLlib_classification</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7e679526a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"241212_01_MLlib_classification\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c65222fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\",'true')\\\n",
    "    .option('inferSchema', 'true')\\\n",
    "    .load(\"data/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa28cf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+-----------+\n",
      "|survived|pclass|   sex| age|sibsp|parch|   fare|embark_town|\n",
      "+--------+------+------+----+-----+-----+-------+-----------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|Southampton|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|  Cherbourg|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|Southampton|\n",
      "|       1|     1|female|35.0|    1|    0|   53.1|Southampton|\n",
      "|       0|     3|  male|35.0|    0|    0|   8.05|Southampton|\n",
      "|       0|     3|  male|null|    0|    0| 8.4583| Queenstown|\n",
      "|       0|     1|  male|54.0|    0|    0|51.8625|Southampton|\n",
      "|       0|     3|  male| 2.0|    3|    1| 21.075|Southampton|\n",
      "|       1|     3|female|27.0|    0|    2|11.1333|Southampton|\n",
      "|       1|     2|female|14.0|    1|    0|30.0708|  Cherbourg|\n",
      "|       1|     3|female| 4.0|    1|    1|   16.7|Southampton|\n",
      "|       1|     1|female|58.0|    0|    0|  26.55|Southampton|\n",
      "|       0|     3|  male|20.0|    0|    0|   8.05|Southampton|\n",
      "|       0|     3|  male|39.0|    1|    5| 31.275|Southampton|\n",
      "|       0|     3|female|14.0|    0|    0| 7.8542|Southampton|\n",
      "|       1|     2|female|55.0|    0|    0|   16.0|Southampton|\n",
      "|       0|     3|  male| 2.0|    4|    1| 29.125| Queenstown|\n",
      "|       1|     2|  male|null|    0|    0|   13.0|Southampton|\n",
      "|       0|     3|female|31.0|    1|    0|   18.0|Southampton|\n",
      "|       1|     3|female|null|    0|    0|  7.225|  Cherbourg|\n",
      "+--------+------+------+----+-----+-----+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef97d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- survived: integer (nullable = true)\n",
      " |-- pclass: integer (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- sibsp: integer (nullable = true)\n",
      " |-- parch: integer (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- embark_town: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e340f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e7c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da14f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2011abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b9565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7cc7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark_start",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
